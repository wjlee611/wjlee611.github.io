{"pageProps":{"posts":[{"title":"Intensity Transformations","description":"이미지 밝기 변환에 대한 내용을 다뤄봅니다.","icon":"","image":"","tags":["Transform Function","Histogram","Equalization"],"draft":false,"date":"2023-10-16 / 21:09","content":"\n## Transform Functions\n\n입력 영상에 대해 밝기값(에너지 레벨)의 변화를 가하고 싶다면 단순히 픽셀값의 데이터에 변화를 가하면 된다.\n\n$$\ns = T(r)\n$$\n\n하지만, 특정 데이터를 어떻게 변화시키는지에 따라 출력 영상이 달라지고, 거기에서 얻을 수 있는 정보도 달라진다.\n그 데이터를 변화시키는 기준인 변환 함수의 종류와, 그 결과를 알아보자.\n\n<notice>\n  얻을 수 있는 정보가 달라진다는 표현을 사용했는데,\n  **강조**하고싶은 정보가 달라진다는 것이지 **실제** 정보량 자체는 변하지 않는다.\n  물론 임의로 특정 밝기 영역을 0으로 만든다면 정보량이 줄어들 수는 있다.\n  하지만 **물리적인 정보량은 절대 늘어나지 않는다**. (사람 눈에 보기 편하게 바꿀 뿐)\n</notice>\n\n### Basic\n\n![231016-212632](/posts/mid_03/231016-212632.png)\n\n이제부터 그래프를 해석하는 능력이 중요해진다.\n예로 들어 `Log` 함수를 변환 함수로 선택한다면 `전반적으로 영상이 밝아짐`을 알 수 있어야 한다.\n$y=-x$ 형태의 `Negative` 함수를 선택한다면 영상 명암이 아래와같이 `반전`될 것이다.\n\n![231016-213010](/posts/mid_03/231016-213010.png)\n\n### Power-Law (Gamma)\n\n위의 기본 함수로는 세부적으로 변화시키기 힘들것이다.\n하지만 아래의 함수를 이용하면 상수값($\\gamma$)를 변화시켜 변환을 세부적으로 처리할 수 있게된다.\n\n$$\ns = cr^\\gamma\n$$\n\n감마값이 커질수록 변환된 영상이 어두워지는 특징이 있다.\n\n![231016-213224](/posts/mid_03/231016-213224.png)\n\n감마 함수는 Gamma correction에 자주 사용되곤 하는데,\n이게 뭐냐면, 출력 장치의 빛의 세기를 조정해 원본 영상과 같은 영상을 디스플레이 할 수 있도록 하는 과정이다.\n\n![231016-213529](/posts/mid_03/231016-213529.png)\n\n### Piecewise-Linear\n\n선형 커브를 여러 범위로 쪼갠 함수로\n특정 범위의 값을 확장하거나, 임의의 값으로 변경할 때 사용한다.\n\n![231016-214238](/posts/mid_03/231016-214238.png)\n\n함수가 좌상단과 같이 주어질 경우 우상단의 이미지가 좌하단의 이미지처럼 변환된다.\n특정 범위의 값을 확장시켜 비슷한 레벨의 빛을 분산시켜 차이를 만든 것이다.\n\n$\\overline{(r_1,s_1)(r_2,s_2)}$의 기울기를 수직으로 만들면 `Threshold` 함수라고 불리우게 되는데,\n그렇게 되면 특정 범위 이하의 빛은 검은색, 이상의 빛은 흰색으로 이분된다.\n\n이러한 처리 기법을 `Contrast Stretching` 라고 부른다.\n\n![231016-214728](/posts/mid_03/231016-214728.png)\n\n이렇게 함수가 주어진 경우에는 영상이 다음과 같이 변환된다.\n\n![231016-214753](/posts/mid_03/231016-214753.png)\n\n특정 부분을 제외한 나머지 영역을 죽이거나, 특정 부분만을 강조할 때 사용하는데,\n이런 처리 기법을 `Intensity-Level Slicing` 라고 부른다.\n\n---\n\n## Histogram Processing\n\n<tip>\n  `Histogram`\n  데이터의 분포를 한 눈에 볼 수 있는 그림 혹은 그래프\n</tip>\n\n영상의 에너지 레벨 분포를 알고싶다면 다음과 같은 과정으로 구할 수 있다.\n\n$$\nh(r_k) = n_k\n$$\n\n여기서 $r_k$는 k번째 gray level(에너지 레벨 0~255)를 나타내고,\n$n_k$는 그 에너리 레벨을 갖는 픽셀의 개수를 의미한다.\n코드로 구현한다면 다음과 같이 구현할 수도 있을것이다.\n\n```cpp:.cpp\nunsigned int Histogram[256] = {0};\n\nfor (h=0; h<H; h++) {\n  for (w=0; w<W; w++) {\n    Histogram[img[w][h]]++;\n  }\n}\n```\n\n하지만 단순 픽셀 수를 세기만 한다면, 매우 큰 영상의 경우 평균적인 빛의 밝기가 어두움에도 값이 크게 나오는 문제가 발생할 수 있다.\n따라서 영상 크기에 따라 자료해석의 차이를 없애도록 영상 크기로 나누어 확률로서 일반화하게 된다.\n\n$$\np(r_k) = \\frac{n_k}{WH}\n$$\n\n이걸 왜 하는건지 알아보기 전에 우선 서로 다른 영상별로 수집된 히스토그램을 살펴보자.\n\n![231016-220848](/posts/mid_03/231016-220848.png)\n\n히스토그램의 분포를 살펴보면 모든 영역에 골고루 분배된 영상이 가장 보기 좋음을 알 수 있다.\n그렇다면 히스토그램 분포를 분산시키는게 영상 품질 개선에 도움이 된다는 것을 알게 되었다.\n\n### Equalization\n\n그렇다면 히스토그램 분포를 골고루 분배할 수 있을까?\n\n![231016-221610](/posts/mid_03/231016-221610.png)\n\n결론부터 말하면 이렇게 이상적으로 분배는 불가능하다.\n0이었던 데이터를 0과 1로 적절히 분산하는 방법이 없기 때문이다.\n\n![231016-222414](/posts/mid_03/231016-222414.png)\n\n이렇게 구현하는 것이 최선일 것이다.\n\n구현에 있어 중요한 점은 **일정 범위 내**의 변환 전과 변환 후의 `확률 분포는 같아야 한다`는 점이다.\n예로 들어 변환 전의 범위 `0~1`은 변환 후의 범위 `0~3`으로 대응되는데, `각 구간의 확률의 합은 동일`함을 알 수 있다.\n이 사실을 식으로 일반화 하면 다음과 같아진다.\n\n$$\n\\sum_{i=0}^{r}p_r(i) = \\sum_{i=0}^{s}p_s(i)\n$$\n\n이를 연속적인 값으로 표현하기 위해 적분식으로 변환하면 다음과 같아진다.\n\n$$\n\\int_{0}^{r}p_r(w)dw = \\int_{0}^{s}p_s(w)dw\n$$\n\n여기서 다시 상기해보자면 $p_r$은 원본 히스토그램 분포(확률 함수)이고, $p_s$는 목표로 하는 히스토그램 분포이다.\n이상적인 확률 함수는 다음 그림과 같을 것이다.\n\n![231016-222950](/posts/mid_03/231016-222950.png)\n\n해당 함수는 $p_s = \\frac{1}{L-1}$ 로 표현 가능한데 이를 위의 적분식에 대입하면 다음과 같이 정리할 수 있다.\n\n$$\n\\int_{0}^{r}p_r(w)dw = \\int_{0}^{s}p_s(w)dw = \\int_{0}^{s}\\frac{1}{L-1}dw = \\frac{s}{L-1} \\\\\n{} \\\\\ns = T(r) = (L-1)\\int_{0}^{r}p_r(w)dw\n$$\n\n이제 이 공식을 이용해서 프로그래밍하기 위해 다시 불연속적인 값의 합으로 바꿔보자.\n\n$$\ns_k = T(r_k) = (L-1)\\sum_{j=0}^{k}p_r(r_j)\n$$\n($k$는 일정 범위에 해당하는 x축의 값이다.)\n\n이 때, $p_r(r_j)$는 위에서 히스토그램의 확률로서 일반화 한 식을 대입하면 된다.\n즉 최종 변환식은 다음과 같다.\n\n$$\ns_k = T(r_k) = \\frac{L-1}{MN}\\sum_{j=0}^{k}n_j \\; , \\;\\; k=0, 1, ..., L-1\n$$\n\n아래 표를 기준으로 연습을 해보자.\n\n| $r_k$ | $n_k$ | $p_r(r_k) = n_k/MN$ | s_k\n|---|---|---|---|\n| $r_0$ = 0 | 790 | 0.19 | $s_0$ = 1.33 &rarr; 1 |\n| $r_1$ = 1 | 1023 | 0.25 | $s_1$ = 3.08 &rarr; 3 |\n| $r_2$ = 2 | 850 | 0.21 | $s_2$ = 4.55 &rarr; 5 |\n| $r_3$ = 3 | 656 | 0.16 | $s_3$ = 5.67 &rarr; 6 |\n| $r_4$ = 4 | 329 | 0.08 | $s_4$ = 6.23 &rarr; 6 |\n| $r_5$ = 5 | 245 | 0.06 | $s_5$ = 6.65 &rarr; 7 |\n| $r_6$ = 6 | 122 | 0.03 | $s_6$ = 6.86 &rarr; 7 |\n| $r_7$ = 7 | 81 | 0.02 | $s_7$ = 7.00 &rarr; 7 |\n$L=8$\n\n$$\ns_0 = T(r_0) = (8-1)\\sum_{j=0}^{0}p_r(r_j) = 7 \\times 0.19 = 1.33 \\\\\ns_1 = T(r_1) = (8-1)\\sum_{j=0}^{1}p_r(r_j) = 7 \\times (0.19 + 0.25) = 3.08 \\\\\n$$\n\n즉, $s_0$가 1이기 때문에, $r_0$(0)에 존재하던 에너지 레벨을 1로 올리고,\n$s_1$가 3이기 때문에, $r_0$(1)에 존재하던 에너지 레벨을 3로 올리는 과정을 거치면 Equalization을 달성할 수 있다.\n\n이련 변환의 경우 히스토그램과 $T(r)$의 그래프는 다음과 같은 모양을 갖게 된다.\n\n![231016-225134](/posts/mid_03/231016-225134.png)\n\n이런 경우 Equalization을 진행한 영상은 원본 영상에 비해 물리적인 정보량은 줄어들게 된다.\n하지만, 사람의 눈으로 보기에는 더 보기 좋은 영상이 된다.\n\n서로 다른 영상에 대해 Equalization을 적용한 예시와 그 $T(r)$ 함수를 살펴보자.\n\n![231016-225624](/posts/mid_03/231016-225624.png)\n![231016-225636](/posts/mid_03/231016-225636.png)\n\n여기서 알 수 있는 점은 원본의 히스토그램 분포가 빽빽하게 모여있을 수록 변환된 영상의 히스토그램 분포에 빈공간이 많이 생긴다는 것이다. (정보량의 손실이 많아진다)\n\n### Specification\n\n하지만 히스토그램을 이용한 Equalization이 만능인 것은 아니다.\n\n![231016-225928](/posts/mid_03/231016-225928.png)\n\n이런 영상처럼 너무 극단으로 몰린 경우에 적용한 결과는 다음과 같이 나올 수 있는데,\n\n![231016-230011](/posts/mid_03/231016-230011.png)\n\n이런 경우에는 단순히 $p_s = \\frac{1}{L-1}$ 를 사용하여 변환 함수를 구하는 것 보다,\n사용자 정의 함수 $p_z$를 만들어서 처리하는게 더 좋은 영상을 만들 수 있다.\n\n![231016-230350](/posts/mid_03/231016-230350.png)","slug":"univ_com-vision/mid_03","readingMinutes":11,"wordCount":936},{"title":"Singal Processing Fundamentals","description":"신호 처리에 대한 기초적인 정보입니다.","icon":"","image":"","tags":["LTI System","Convolution","Fourier Transform"],"draft":false,"date":"2023-10-15 / 21:57","content":"\n## LTI System\n\nLinear Time Invariant System은 다음과 같은 성질을 갖는다.\n\n1. Linear\n  선형성을 유지한다.\n\n  <tip>\n    `선형성`\n\n    $$\n    H[a_if_i(x,y) + a_jf_j(x,y)] \\\\\n    = a_iH[f_i(x,y)] + a_jH[f_j(x,y)] \\\\\n    = a_ig_i(x,y) + a_jg_j(x,y)\n    $$\n  </tip>\n\n2. Time Invariant\n  시간에 대해 불변성을 갖는다.\n  즉, 시간이 변해도 delay만 있을 뿐, 동일한 input에 대해 동일한 output을 내보낸다.\n\n### System Response\n\n신호 처리를 위해 신호를 디지털화 한 다음 변환(filter)을 가해서 다시 연속적인 신호로 변환하기 위한 과정을 살펴보자.\n\n![231015-222017](/posts/mid_02/231015-222017.png)\n\n우선 신호를 특정 구간에서 일정한 값으로 근사한다.\n그리고 특정 구간에 대해 근사된 데이터에 변환(filter)를 가한다. \n(참고로 filtering에 대해선 추후에 소개할 예정. 지금은 LTI System을 이용해서 신호를 변환하는 과정만 살펴보자.)\n\n그렇게 변환된 데이터를 다시 연속적인 신호로 변환하기 위해선 LTI System에 Pulse를 적용한 결과를 응용하면 된다.\n\n![231015-222538](/posts/mid_02/231015-222538.png)\n\n넓이가 1인 Pulse를 LTI System에 통과시키면 위와 같은 그래프로 변형된다고 하자.\n이 때, LTI System은 선형성을 유지하고 시간 불변성을 갖기 때문에 Pulse의 세기가 커지거나, 시간이 shift돼도,\nLTI System을 통과해도 그 변화가 유지된다.\n\n그렇기에 위에서 변환된 데이터를 특정 구간에 대해 Pulse라고 생각한다면,\n그 데이터를 LTI System에 통과시키면 다음과 같이 변환될 것이다.\n\n![231015-222954](/posts/mid_02/231015-222954.png)\n\n## Convolution\n\n위에서 언급한 Pulse에 대해 단위 시간(T)를 0에 가깝게 보내면 연속적인 신호에 대한 Pulse가 되는데, 이를 Impulse라고 한다.\n이런 Impulse를 LTI System에 통과시키면 위에서 봤던 그래프 형태로 나오게 되는데, 이를 임펄스 반응 이라고 하고, $h(t)$ 라고 하자.\n\n![231015-223956](/posts/mid_02/231015-223956.png)\n\n입력 신호 $f$와 출력 신호 $y$는 다음과 같은 관계를 갖게 된다.\n\n$$\ny(t) = f(t) * h(t)\n$$\n\n즉, LTI System의 출력($y$)은 시스텝의 임펄스 반응($h$)과 입력($f$)의 Convolution이다.\n\n## Fourier Transform\n\n![231015-224927](/posts/mid_02/231015-224927.png)\n\n푸리에 변환의 기본적인 아이디어는 주기적인 어떠한 함수는 모두 sin파 또는 cos파의 합으로 표현(근사)될 수 있다에서 출발한다.\n\n푸리에 변환을 거치면 시간에 대한 함수가 주파수에 대한 함수로 변환되는데,\n시간 축이 주파수 축으로 변환된다는 뜻이다.\n단적인 예로, 주기가 $2\\pi$이고, 크기가 1인 sin함수는 크기가 1이고, $u=1 (2\\pi)$인 Impulse 형태로 그려진다.\n\n<tip>\n  `푸리에 변환`\n  $$\n  F(u) = \\int_{-\\infty}^{\\infty} f(x)e^{-i2\\pi ux}dx\n  $$\n\n  `역 푸리에 변환`\n  $$\n  f(x) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} F(u)e^{iux}dx\n  $$\n</tip>\n\n그런데 왜 푸리에 변환을 알아야 할까?\n바로 푸리에 변환을 사용하면 Convolution 연산이 매우 간단한 형태로 변환되기 때문이다.\n\n$$\nG(u) = \\int_{-\\infty}^{\\infty}g(x)e^{-i2\\pi ux}dx \\\\\n= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f(\\tau)h(x-\\tau)e^{-i2\\pi ux}dx \\\\\n= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}[f(\\tau)e^{-i2\\pi u\\tau}d\\tau][h(x-\\tau)e^{-i2\\pi u(x-\\tau)}dx] \\\\\n= \\int_{-\\infty}^{\\infty}[f(\\tau)e^{-i2\\pi u\\tau}d\\tau]\\int_{-\\infty}^{\\infty}[h(x')e^{-i2\\pi ux'}dx'] \\\\ \n= F(u)H(u)\n$$\n\n즉, 기존 도메인($x$)에서의 Convolution 연산이 푸리에 변환된 주파수 도메인($u$)에서는 단순 곱셈으로 표현된다.\n\n![231015-230238](/posts/mid_02/231015-230238.png)\n\n따라서 Convolution 연산을 간단하게 하기 위해서는 일단 푸리에 변환 후 곱연산을 수행해서 다시 역 푸리에 변환을 거치는 과정을 수행하는게 좋다.\n\n### Sampling\n\n[**`이전 포스트`**](https://wjlee611.github.io/blog/univ_com-vision/mid_01#aliasing)에서 Sampling이 적으면 Aliasing이 발생한다고 했었는데, 그 이유을 알아보자.\n\n![231015-230835](/posts/mid_02/231015-230835.png)\n\n왼쪽은 시간 도메인 기준으로 입력 신호에 적절하게 샘플링된 Impulse를 Convolution하면 좌하단처럼 샘플링이 이루어진다.\n오른쪽은 왼쪽을 푸리에 변환한 결과로 Convolution 대신 곱연산한 결과이다.\n\n~~(본인도 이해는 안되지만)~~ 여기서 중요한 것은 샘플링이 촘촘할 수록\n푸리에 변환된 스펙트럼이 듬성듬성 해진다는 점이다.\n\n만약, 샘플링이 적은수가 되었다면 우하단의 입력 신호의 스펙트럼 봉우리(?)가 오버랩될 것이다.\n오버랩 되는 경우 원본을 복구할 수 없기에 Aliasing이 발생하는 것이다.","slug":"univ_com-vision/mid_02","readingMinutes":6,"wordCount":449},{"title":"Digital Image Fundamentals","description":"디지털 이미지에 대한 기초적인 정보입니다.","icon":"","image":"","tags":["Sampling","Quantization","Interpolation"],"draft":false,"date":"2023-10-15 / 20:05","content":"\n## Sampling & Quantization\n\n연속적인 자연계의 현상을 기록하기 위해서는 이미지를 불 연속적인 형태. 즉, 디지털로 변환해야 한다.\n\n예로 들어 이미지의 좌표가 100.32라면? 반올림을 하던지 적당히 100과 같은 불 연속적인 값으로 치환해야 하며,\n에너지레벨 역시 이와 같은 방식으로 디지털화 해야한다.\n\n이렇게 자연계의 연속적인(무한한) 값을 `디지털화 하기 위해 유한하게` 자르는 과정을 `Sampling`이라 하고,\n무한 소수의 데이터를 `양자화시켜 비트에 저장할 수 있게` 자르는 과정을 `Quantization`라고 한다.\n\n![231015-201653](/posts/mid_01/231015-201653.png)\n\n**좌상단**의 이미지 중에서 $\\overline{AB}$ 를 디지털화 해본다면,\n**우상단**의 그래프처럼 에너지레벨(빛의 밝기)이 표현될 것이다. (지글지글 거리는 것은 센서의 한계로인한 노이즈)\n샘플링을 일정 구간으로 잘라 네모난 점으로 표현하면 **좌하단**의 이미지처럼 될 것이고,\n이를 양자화하면 **우하단**의 이미지처렴 변화하여 디지털로 저장할 수 있게 된다.\n\n![231015-202204](/posts/mid_01/231015-202204.png)\n\n이런 방식으로 2차원 이미지를 디지털화 하면 위와 같은 모양이 될텐데,\n연속적인 데이터를 불연속적인 데이터로 변환하면서 어쩔 수 없는 데이터의 손실이 발생할 수 있다.\n\n<tip>\n  픽셀의 가로축은 x축, 세로축은 y축이며,\n  x좌표는 늘 보던 좌표계와 마찬가지로 오른쪽으로 갈 수록 커지지만,\n  y좌표는 반대로 내려갈수록 커진다. **(y축 반전 주의)**\n  <br />\n  M행 N열(M$\\times$N)의 이미지는 다음과 같은 배열에 저장할 수 있다.\n\n  $$\n  f(x,y) = \\begin{bmatrix}\n  f(0,0) & f(0,1) & ... & f(0,N-1) \\\\\n  f(1,0) & f(1,1) & ... & f(1,N-1) \\\\\n  ... & ... & ... & ... \\\\\n  f(M-1,0) & f(M-1,1) & ... & f(M-1,N-1) \\\\\n  \\end{bmatrix}\n  $$\n</tip>\n\n### Aliasing\n\n![231015-205116](/posts/mid_01/231015-205116.png)\n\n샘플링을 위 이미지와 같이 극단적으로 적게 할 경우, 조건이 없다면 원본 데이터를 유추할 수 없게 된다.\n또는 변화량이 너무 큰 경우에도 위와 같은 Aliasing 현상이 발생할 수 있다.\n예로 들어서 선풍기를 영상으로 찍으면 멈춰있는 듯한 현상이 그런 경우이다.\n\n### Quantization Level\n\n![231015-204846](/posts/mid_01/231015-204846.png)\n\n양자화를 얼마나 세밀하게 할지를 Quantization Level이 결정한다.\n레벨이 적을수록 듬성듬성 양자화하게 되고(점선 간격이 늘어남), 이는 화질 저하로 이어진다.\n하지만 용량은 절약될 것이다.\n\n### Size (Storage bits)\n\n이렇게 저장된 영상의 크기를 구해보자.\n\n<notice>\n  이미지의 화질은 M$\\times$N으로 가정하고,\n  각 픽셀은 0~255, 즉, 8 bits의 에너지 레벨을 갖는다고 가정하자.\n</notice>\n\n단색 이미지(Gray Image)의 경우 1픽셀은 8bits가 필요하기에 1byte.\n이 픽셀이 M$\\times$N개 있으니 M$\\times$Nbytes.\n컬러 이미지의 경우 RGB 3개의 색상 채널이 있으니 3을 곱해서 M$\\times$N$\\times$3bytes 가 된다.\n\n위 계산 결과는 하나의 이미지에 대한 사이즈로, 동영상의 경우에는 30프레임의 경우 추가로 30을 더 곱해줘야 할 것이다.\n\n### Saturation\n\n![231015-203543](/posts/mid_01/231015-203543.png)\n\n센서까지 차이가 있던 데이터가 샘플링 과정에서 차이가 없어지는, Saturation 현상이 발생할 수 있다.\n\n### Gray Level\n\n![231015-203931](/posts/mid_01/231015-203931.png)\n![231015-203946](/posts/mid_01/231015-203946.png)\n\nGray Level이 높을 수록 에너지 레벨을 세분화해서 표현할 수 있다.\n따라서 디스플레이 장치가 좋지 않아서 Gray Level이 낮을 경우 같은 이미지라도 위 사진처럼 다르게 표현될 수 있다.\n\n## Interpolation\n\n디지털화된 이미지의 사잇값을 적절히 채워 실제 데이터를 추측하는 과정,\n또는, 저화질의 영상의 픽셀값을 채워 고화질로 바꾸거나, 영상의 회전, 축소시 픽셀값을 추측하는 과정을 Interpolation 라고 한다.\n\n### Pixel math\n\n보통 아래와 같은 행렬간의 연산 혹은 픽셀별 계산으로 처리된다.\n\n$$\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22} \\\\\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_{11} & b_{12} \\\\\nb_{21} & b_{22} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11} + b_{11} & a_{12} + b_{12} \\\\\na_{21} + b_{21} & a_{22} + b_{22} \\\\\n\\end{bmatrix}\n$$\n\n$$\n\\begin{bmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nb_{11} & b_{12} \\\\\nb_{21} & b_{22} \\\\\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\\\\na_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22} \\\\\n\\end{bmatrix}\n$$\n\n단, 보통 픽셀값은 0~255 사이의 값을 갖기 때문에, overflow, underflow에 대해 적절하게 처리해줘야 한다.\n\n### Linear\n\n$H[f(x,y)] = g(x,y)$ 와 같은 변환 함수 $H$가 있을 때,\n아래의 특성을 만족하면 $H$가 선형이라고 한다.\n\n$$\nH[a_if_i(x,y) + a_jf_j(x,y)] \\\\\n= a_iH[f_i(x,y)] + a_jH[f_j(x,y)] \\\\\n= a_ig_i(x,y) + a_jg_j(x,y)\n$$\n\n즉 연산 순서에 상관없다면 선형이라 하며, 대부분의 이미지 처리 연산은 선형이다.\n\n### Image Rotation\n\n![231015-212235](/posts/mid_01/231015-212235.png)\n\n특정 픽셀을 $\\theta$만큼 반 시계방향으로 회전시킬 경우 아래와 같은 연산을 가해주면 된다.\n\n$$\n\\begin{bmatrix}\nx' \\\\\ny'\n\\end{bmatrix}\n=\nR(\\theta)\n\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ncos\\theta & -sin\\theta \\\\\nsin\\theta & cos\\theta\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix}\n$$\n\n하지만, 이 경우에는 원점을 중심으로 회전되기 때문에,\n영상을 중심으로 회전시켜야 하는 경우에는 다음과 같은 스탭을 거쳐야 한다.\n\n1. 영상을 중심으로 평행 이동 시킨다.\n2. 삼각함수를 이용해 영상을 회전시킨다.\n3. 다시 영상을 원위치로 평행 이동 시킨다.\n\n하지만, 위 연산은 선형이기 때문에 각 픽셀별로 아래 하나의 연산으로 처리해도 상관없다.\n\n$$\n\\begin{bmatrix}\nx' \\\\\ny'\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ncos\\theta & -sin\\theta \\\\\nsin\\theta & cos\\theta\n\\end{bmatrix}\n\\begin{bmatrix}\nx - W/2\\\\\ny - H/2\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nW/2\\\\\nH/2\n\\end{bmatrix}\n$$\n\n<notice>\n  영상 변환을 하기 위해서는 `변환 후(x, y)`의 좌표를 연산을 통해 `변환 전(x', y')`의 좌표를 구하고,\n  그 좌표의 데이터를 가져와 Quantization하여 변환 후의 좌표에 대입하는 과정을 거쳐야 한다.\n</notice>\n\n### Image Interpolation\n\n![231015-214108](/posts/mid_01/231015-214108.png)\n\n검은색 input 영상을 흰색 output 영상으로 upscaling하거나, 영상 회전과 같이\n변환 후의 영상의 좌표가 픽셀에 정확히 들어가지 않는 경우, 검은색 픽셀값을 이용해 흰색 픽셀값을 추측해야 한다.\n추측하는 방식에는 보통 아래와 같은 방법들이 있다.\n\n1. Replication\n  이전 픽셀값의 데이터를 그대로 사용하는 방법이다.\n2. Nearest Neighbor\n  본인과 가까운 픽셀의 데이터를 그대로 사용하는 방법이다.\n\n위 두 방법의 경우 Interpolation은 가능하지만, 이미지 화질의 개선이 이루어지지는 않는다.\n적당한 화질 개선을 위해서는 아래의 방법을 고려해볼 수 있다.\n\n3. (Bi)linear Interpolation\n  근처 픽셀값을 이용해 평균 데이터를 계산하여 사용하는 방법이다.\n\n![231015-214947](/posts/mid_01/231015-214947.png)\n\n$$\nq_1 = (1-a)p_1 + ap_2 \\\\\nq_2 = (1-a)p_3 + ap_4 \\\\\n{} \\\\ \nq = (1-b)q_1 + bq_2\n$$\n","slug":"univ_com-vision/mid_01","readingMinutes":10,"wordCount":824},{"title":"대학 - 컴퓨터비전","description":"3학년 2학기 컴퓨터비전 수업 아카이브","icon":"","image":"","tags":[],"draft":false,"date":"2023-09-06 / 12:20","content":"","slug":"univ_com-vision/index","readingMinutes":0,"wordCount":1}]},"__N_SSG":true}