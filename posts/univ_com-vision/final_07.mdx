---
title: 'Face Recognition'
description: '얼굴을 인식하는 방법과 그에 사용되는 선형대수학을 다뤄봅니다.'
icon: ''
image: ''
tags:
  - SVD
  - PCA
draft: false
date: 2023-12-03 14:07:46
---

## SVD

Singular Value Decomposition은 행렬을 여러 행렬로 분해하는 방법이다.
보통 아래와 같은 기호로 표현한다.

$A = U$ $\sum$ $V^T$

행렬 A는 세 행렬로 분해되는데, 각 행렬이 어떤 특성을 갖는지 알아보자.

![231203-141325](/posts/final_07/231203-141325.png)

우선 SVD된 행렬에서 $U$, $V^T$는 normalize 되어있다.
그리고, $\sum$는 대각 행렬인데, 원소가 내림차순으로 정렬되어 있다.

여기서 대각행렬이 내림차순으로 정렬된다는 특징이 매우 중요한데, 왜 중요한지 아래의 예시를 보며 알아보자.

$$
\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6
\end{bmatrix} = \\
\begin{bmatrix}
-0.39 & -0.92 \\
-0.92 & 0.39
\end{bmatrix} \times \begin{bmatrix}
9.51 & 0 & 0 \\
0 & 0.77 & 0
\end{bmatrix} \times \begin{bmatrix}
-0.42 & -0.57 & -0.70 \\
0.81 & 0.11 & -0.58 \\
0.41 & -0.82 & 0.41
\end{bmatrix}
$$

여기서 $U$와 $\sum$을 먼저 계산하자.

$$
\begin{bmatrix}
-3.68 & -0.71 & 0 \\
-8.8 & 0.30 & 0
\end{bmatrix} \times \begin{bmatrix}
-0.42 & -0.57 & -0.70 \\
0.81 & 0.11 & -0.58 \\
0.41 & -0.82 & 0.41
\end{bmatrix}
$$

$\sum$이 내림차순 정렬되어 있었기 때문에 $U \sum$의 1열의 값이 크고, 2열은 값이 작은 것을 확인할 수 있다.

이 때, 위 두 행렬 $U \sum$ 와 $V^T$ 의 i열 i행의 원소만을 가지고 $A_{pi}$ 를 만들어보자.

$$
\begin{bmatrix}
{\color{Red} -3.68} & -0.71 & 0 \\
{\color{Orange} -8.8} & 0.30 & 0
\end{bmatrix} \times \begin{bmatrix}
{\color{Red} -0.42} & {\color{Orange} -0.57} & {\color{Orange} -0.70} \\
0.81 & 0.11 & -0.58 \\
0.41 & -0.82 & 0.41
\end{bmatrix} \\
= {\color{Orange} \begin{bmatrix}
{\color{Red} 1.6} & 2.1 & 2.6 \\
3.8 & 5.0 & 6.2
\end{bmatrix}} = A_{p1}
$$

$$
\begin{bmatrix}
-3.68 & {\color{Orange} -0.71} & 0 \\
-8.8 & {\color{Orange} 0.30} & 0
\end{bmatrix} \times \begin{bmatrix}
-0.42 & -0.57 & -0.70 \\
{\color{Orange} 0.81} & {\color{Orange} 0.11} & {\color{Orange} -0.58} \\
0.41 & -0.82 & 0.41
\end{bmatrix} \\
= {\color{Orange} \begin{bmatrix}
-0.6 & -0.1 & 0.4 \\
0.2 & 0 & -0.2
\end{bmatrix}} = A_{p2}
$$

즉, $\sum$의 크기 비율에 맞게 $A$를 $A_{p1}$, $A_{p2}$로 분해할 수 있다.

근데 이걸 왜 했느냐?
A를 6픽셀의 영상이라고 했을 때, A를 2개의 영상으로 분해한 꼴이다.
이 때, 에너지 레벨이 큰 영상부터 작은 영상 순서대로 분해한 것인데, **에너지 레벨이 크다**는 것은 **가장 두드러지는 특징**을 의미한다.
즉, 사람 얼굴을 예로 들면, 위의 partial 영상부터 타원모양, 눈코입 위치, 피부 질감과 같이 큰 특징 순으로 얼굴영상을 분해한 것이다.

위 예시는 2개의 특징으로밖에 분리를 못하였지만, 아래의 예시를 살펴보자.

![231203-143845](/posts/final_07/231203-143845.png)

특징을 300개를 추출했는데, 그 중 상위 10개의 특징들로만 영상을 재구성하였다.
단, 3%만의 특징으로만 영상을 복원했는데, 상당히 원본을 닮을 수 있는 이유는 아래에서 알아보자.

---

## PCA

Principal Component Analysis는 주성분 분석이라고 하는데, 이를 이용하면 고차원 데이터를 저차원 데이터로 차원 축소를 시킬 수 있다.
그런데 그 과정에서 데이터의 손실이 최소화 되도록 하는데, 어떤식으로 최소화 하는지 알아보자.

![231203-145410](/posts/final_07/231203-145410.png)

키, 몸무게로 표현된 2차원 데이터가 있다.
이 데이터를 1차원으로 잘 낮춰보기 위해 PCA를 사용하자.

![231203-145633](/posts/final_07/231203-145633.png)

특정 직선에 수선의 발을 내렸을 때, 평균으로부터 수선의 발 까지의 길이의 제곱의 합이 최대가 되도록 하는 최적의 직선을 찾는다.

![231203-145832](/posts/final_07/231203-145832.png)

그리고, 그 최적의 직선에 수직인 다른 직선을 긋는다.

![231203-150105](/posts/final_07/231203-150105.png)

각 PC축이 전체 데이터를 얼마나 잘 표현하고 있는지 분석하기 위해 회전한다.
여기서 이 회전은 SVD의 $U$ 행렬변환에 해당한다.

![231203-150324](/posts/final_07/231203-150324.png)

그리고 각 축이 데이터를 얼마나 잘 표현하는지에 대한 척도로 평균과 수선의 발까지의 거리의 제곱의 합으로 분석한다.
여기서 분석 결과가 SVD의 $\sum$ 행렬에 해당한다.

만약 PC1이 PC2 보다 압도적으로 전체 데이터를 잘 표현한다면?

![231203-150637](/posts/final_07/231203-150637.png)

PC1 만으로도 전체 데이터를 표현해도 크게 상관 없을 것이다.
따라서 PC2를 사용하지 않음으로써 차원을 낮출 수 있다.

![231203-144044](/posts/final_07/231203-144044.png)

대부분의 주요 특징은 높은 에너지 레벨을 보이고, 사소하고 디테일한 특징은 낮은 에너지 레벨을 보이기 때문에,
SVD에서 상위 몇개의 특징만으로 원본 영상을 비슷하게 재현할 수 있는 것이다.

---

## Face Recognition

이제 기본 배경 지식을 어느정도 알았으니, 얼굴 인식하는 방식에 대해 알아보자.

![231203-150956](/posts/final_07/231203-150956.png)

100x100 pixel의 얼굴 영상은 1만 차원의 하나의 포인트로 대응된다.

![231203-151306](/posts/final_07/231203-151306.png)

즉, 1만개의 특징 중, 얼굴을 표현하는 상위의 특징들로 차원을 축소한다면?
얼굴인 영상만을 인식할 수 있을 것이다.

따라서 PCA를 이용해서 얼굴의 가장 큰 특징벡터(sub-space)를 찾는 방식으로 얼굴 인식을 할 수 있으며,
sub-space는 학습 데이터를 학습을 시켜 얼굴의 eigenvector 들을 구하는 방식으로 진행된다.

![231203-151850](/posts/final_07/231203-151850.png)

얼굴의 특징을 나타내는 eigenvector를 구했다면, 이를 이용해서 여러 얼굴을 만들수도 있다.

![231203-151927](/posts/final_07/231203-151927.png)

이러한 여러 얼굴은 아래의 공식으로 표현할 수 있다.

$$
x_i \approx \mu + a_1 \phi _1 + a_2 \phi _2 + ... + a_k \phi _k
$$

여기서 중요한 점은 특징을 1만개를 사용하여 얼굴을 만든 것이 아니라, k개 만을 가지고 만들었다는 점이다.
즉, 1만 차원의 얼굴 영상을 단 k차원으로 줄여서 파악할 수 있다.