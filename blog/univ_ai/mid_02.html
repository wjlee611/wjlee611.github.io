<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>웅덩이</title><link rel="canonical" href="https://wjlee611.github.io/blog/univ_ai/mid_02"/><meta name="next-head-count" content="4"/><link rel="icon" href="/images/icon_circle.png"/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" rel="stylesheet"/><meta name="description" content="웅덩이"/><meta name="apple-mobile-web-app-title" content="웅덩이"/><meta name="application-name" content="웅덩이"/><meta name="theme-color" content="#009c39"/><meta name="google-site-verification" content="vhQ9DaDdUJcSBHKI_U6tAtE61zwz2i2pLQXyZ62GRLk"/><meta name="naver-site-verification" content="07764cc1a8eda55b4bdf78cf846d6811d042b9ee"/><link rel="preload" href="/_next/static/media/a37cf3809adb2c63-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/dd50543ba70be8e9-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/media/c372a630cbda84f2-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"/><link rel="preload" href="/_next/static/css/553b0c3f635f266c.css" as="style"/><link rel="stylesheet" href="/_next/static/css/553b0c3f635f266c.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-b8f8d6679aaa5f42.js" defer=""></script><script src="/_next/static/chunks/framework-401a9806b070f31a.js" defer=""></script><script src="/_next/static/chunks/main-6b74302918225334.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b6a4b29518e66136.js" defer=""></script><script src="/_next/static/chunks/95b64a6e-5c1c80ce1af5e491.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...slugs%5D-d30256c1e19801d0.js" defer=""></script><script src="/_next/static/deatTRx3qrRnvuKFWMv7Z/_buildManifest.js" defer=""></script><script src="/_next/static/deatTRx3qrRnvuKFWMv7Z/_ssgManifest.js" defer=""></script></head><body class="text-primary transition-[background] bg-white dark:bg-[#1A1C23]"><script>
            const theme = localStorage.getItem("theme");
            const getUserTheme = () => {
             if(theme){
              return theme
             } 
             return window.matchMedia('(prefers-color-scheme: dark)').matches
             ? 'dark'
             : 'light'
          }
          document.body.dataset.theme = getUserTheme();
          </script><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="__className_e7b8b0 text-center transition-all "><header class="fixed top-0 left-0 right-0 mx-anuo w-screen h-12 md:h-16 flex justify-between items-center px-2 md:px-10 backdrop-blur bg-blue-200 bg-opacity-20 z-50"><div class="h-full flex items-center"><a class="h-full aspect-square flex justify-center items-center text-3xl select-none cursor-pointer" href="/">🫧</a><nav class="h-full hidden md:flex space-x-8 overflow-hidden ml-10"><li class="h-full flex items-center list-none relative select-none"><a class="h-full w-full md:w-auto flex items-center transition-colors py-2 md:my-0 font-bold text-black dark:text-white " href="/">Portfolio</a></li><li class="h-full flex items-center list-none relative select-none"><a class="h-full w-full md:w-auto flex items-center transition-colors py-2 md:my-0 font-bold text-blue-500 " href="/blog">Blog</a><div class="hidden md:flex w-full h-[2px] bg-blue-500 absolute bottom-0 left-0 blur-[2px]"></div></li><li class="h-full flex items-center list-none relative select-none"><a class="h-full w-full md:w-auto flex items-center transition-colors py-2 md:my-0 font-bold text-black dark:text-white " href="/arkhive">Arkhive</a></li></nav></div><div class="flex items-center h-full"><button aria-label="Toggle Dark Mode" type="button" class="flex h-9 w-9 items-center justify-center rounded-lg transition-all text-secondary hover:bg-secondary "><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" class="h-6 w-6 text-yellow-400 drop-shadow-base"></svg></button><button class="flex md:hidden items-center justify-center w-16 h-full text-2xl text-black dark:text-white"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.5 11.5A.5.5 0 0 1 5 11h10a.5.5 0 0 1 0 1H5a.5.5 0 0 1-.5-.5zm-2-4A.5.5 0 0 1 3 7h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm-2-4A.5.5 0 0 1 1 3h10a.5.5 0 0 1 0 1H1a.5.5 0 0 1-.5-.5z"></path></svg></button></div></header><main class="inline-block w-full relative pt-16 px-8 max-w-5xl 2xl:max-w-7xl" style="opacity:1;transform:none"><div class="flex flex-col items-start pb-16"><header class="flex w-full flex-col items-center my-10"><h1 class="bg-gradient-to-br from-blue-600 to-blue-400 bg-clip-text text-transparent text-3xl font-bold mb-5 drop-shadow">게임에서의 탐색 및 최적화</h1><span class="text-blue-500 text-lg">게임 트리를 탐색하는 기법과 최적화에 대해 알아봅니다.</span><span class="space-x-10 mt-5 text-blue-400 text-sm">읽는데<span class="text-blue-500 text-xl font-semibold"> <!-- -->11</span>분 정도 걸려요.</span></header><section class="w-full flex justify-between space-x-5"><div class="w-full flex flex-col items-start prose dark:prose-dark max-w-full lg:max-w-2xl 2xl:max-w-4xl"><h2 id="게임-트리"><a class="anchor" href="#게임-트리"><span class="icon icon-link"></span></a>게임 트리</h2>
<p><code>상대가 있는 게임</code>에서 자신과 상대방의 가능한 게임 상태를 나타낸 트리.<br/>
<!-- -->자신의 턴인지, 상대의 턴인지에 따라 탐색하는 방식이 다르게 적용됨.<br/>
<!-- -->(나에겐 유리하게, 상대에겐 불리하게)</p>
<p>정해진 시간 내에 최대한 많은 수를 보는 것이 유리하기 때문에 탐색 효율을 높이는 것이 중요하다.</p>
<h3 id="mini-max-algorithm"><a class="anchor" href="#mini-max-algorithm"><span class="icon icon-link"></span></a>Mini-max Algorithm</h3>
<p>특이하게 단말 노드로부터 위로 올라가면서 최소-최대 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 값을 선택하는 방법이다.</p>
<p>자신의 턴인 Max 노드에서는 자신에게 유리한 값을 선택하고,<br/>
<!-- -->상대의 턴인 Min 노드에서는 상대에게 불리한 값을 선택하는 방식을 취한다.</p>
<p><img src="/posts/mid_02/231021-230224.png" alt="231021-230224"/></p>
<p>하지만 트리가 넓을 수록 모든 상태공간을 탐색하는건 시간상 너무 오래 걸리기 때문에 최적화 기법이 들어가야 한다.<br/>
<!-- -->바로 <strong><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>−</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\alpha - \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span> 가지치기(prunning)</strong> 기법이다.</p>
<p>검토해 볼 필요가 없는 부분을 탐색하지 않도록 하는 기법인데, 어떻게 해야 검토할 필요가 없다는 걸 알 수 있을까?</p>
<p>깊이 우선 탐색(DFS)로 제한 깊이까지 탐색을 하면서 Min, Max 노드의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span>값을 업데이트 하는데, 각 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span>값은 다음과 같은 값을 저장한다.</p>
<ul>
<li>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></span><br/>
<!-- -->Max 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최댓값을 저장함</p>
</li>
<li>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span><br/>
<!-- -->Min 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최솟값을 저장함</p>
</li>
</ul>
<p>이 때, 탐색 후 값을 업데이트 하다가 <strong><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>≥</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\alpha \geq \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span></strong> 되는 순간이 오는데, 그 때부터 나머지 자식노드는 탐색할 필요가 없어진다.<br/>
<!-- -->그 이유는, 상한선(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></span>)과 하한선(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span>)이 정해질 때, 그 부모노드의 상한선과 하한선을 넘지 못하면 부모노드를 업데이트 할 수 없기에, 업데이트를 할 가능성이 없다면 가지치기를 해버리는 것이다.</p>
<p>알고리즘의 이해가 안된다면 아래 영상을 참고하면 좋을 거 같다.</p>
<iframe width="100%" height="auto" class="aspect-video" src="https://www.youtube.com/embed/_i-lZcbWkps" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
<p>속성으로 빠르게 탐색하고 싶다면 이런 방식으로 탐색해도 된다.</p>
<iframe width="100%" height="auto" class="aspect-video" src="https://www.youtube.com/embed/6qN5ReC2SUA" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
<p>빠르게 업데이트 가능한 조건을 적어놓고, 그 조건이 업데이트가 절대로 불가능하다면 나머지 노드를 가지치기 하는 방식이다.</p>
<h3 id="몬테카를로-트리-탐색-기법-monte-carlo-simulation"><a class="anchor" href="#몬테카를로-트리-탐색-기법-monte-carlo-simulation"><span class="icon icon-link"></span></a>몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)</h3>
<p><img src="/posts/mid_02/231022-003000.png" alt="231022-003000"/></p>
<p>탐색 공간을 무작위 표본추출을 하면서 탐색 트리를 확장하여 가장 좋아보이는 것을 선택하는 휴리스틱 탐색 방법으로,<br/>
<!-- -->시간이 허용되는 동안 위의 4단계를 반복하여 시뮬레이션 및 트리를 확장한다.</p>
<ol>
<li>
<p>선택<br/>
<!-- -->선택은 <strong>트리 정책</strong>을 적용하여 선택한다.<br/>
<!-- -->정책은 개발자 마음대로 정하는 거지만, 보통 승률과 노드 방문횟수를 고려하여 선택한다.<br/>
<!-- -->일반적으로 <code>승률이 높으며</code>, <code>방문횟수가 적은</code> 노드에 우선권을 부여한다 (UCB, Upper Confidence Bound 정책).</p>
</li>
<li>
<p>확장<br/>
<!-- -->단말 노드에서 트리 정책에 따라 노드를 추가한다.</p>
</li>
<li>
<p>시뮬레이션<br/>
<!-- -->기본 정책에 의한 <code>몬테카를로 시뮬레이션</code>을 적용한다.<br/>
<!-- -->무작위 선택, 또는 약간 똑똑한 방법으로 게임이 끝날 때 까지 진행한다.</p>
</li>
</ol>
<tip><p><code>몬테카를로 시뮬레이션</code></p><br/><p>특정 확률 분포로 부터 무작위 표본(또는 약간 똑똑한 방법으로)을 생성하고, 이 표본에 따라 행동을 하는 과정을 반복하여 결과를 확인하고 이 과정을 반복해 최정 결정을 하는 것.</p><br/><p>특정 상태의 유불리를 상태판단함수로 판단하는 것이 아닌, 시뮬레이션으로 판단하게 된다.</p></tip>
<ol start="4">
<li>역전파<br/>
<!-- -->게임의 결과를 단말 노드에서 루트 노드까지 올라가면서 반영한다.</li>
</ol>
<hr/>
<h2 id="제약조건-만족-문제"><a class="anchor" href="#제약조건-만족-문제"><span class="icon icon-link"></span></a>제약조건 만족 문제</h2>
<p>주어진 제약조건을 만족하는 조합 해(combination solution)을 찾는 문제로 N-Queens problem과 같은 문제가 이에 해당한다.</p>
<h3 id="백-트래킹-탐색-backtracking-search"><a class="anchor" href="#백-트래킹-탐색-backtracking-search"><span class="icon icon-link"></span></a>백 트래킹 탐색 (Backtracking search)</h3>
<p>깊이 우선 탐색(DFS)을 하는 것처럼 변수에 허용되는 값을 하나씩 대입해보고, 가능한 모든 값을 대입했는데도 만족하는 것이 없으면 이전 단계로 돌아가서 이전 단계의 변수에 다른 값을 대입하는 전형적인 백 트래킹 방식이다.</p>
<h3 id="제약조건-전파-constraint-propagation"><a class="anchor" href="#제약조건-전파-constraint-propagation"><span class="icon icon-link"></span></a>제약조건 전파 (Constraint propagation)</h3>
<p>인접 변수 간의 제약 조건에 따라 각 변수에 허용될 수 없는 값들을 제거하는 방식으로, 이름 그대로 주변에 제약조건을 전파하여 선택 가능한 가지수를 줄여가는 방식이다.</p>
<p><img src="/posts/mid_02/231022-004410.png" alt="231022-004410"/></p>
<p>A에 1을 선택하는 순간 B~D에 각각 제약사항이 전파되어 B~D에서 선택할 수 있는 가지수가 제한된다.<br/>
<!-- -->여기서 B가 3을 선택하는 순간 C, D에 각각 제약사항이 또 전파되는데, 이 때 C는 더이상 아무것도 선택할 수 없기에 이전 스탭에서 다른 제약사항을 걸어야 한다.</p>
<hr/>
<h2 id="최적화"><a class="anchor" href="#최적화"><span class="icon icon-link"></span></a>최적화</h2>
<p>여러가지 가능, 혀용되는 값들 중에서 주어진 기준을 가장 잘 만족하는 것을 선택하는 것으로, 크게 <code>조합 최적화</code>와 <code>함수 최적화</code>로 나뉜다.</p>
<h3 id="조합-최적화"><a class="anchor" href="#조합-최적화"><span class="icon icon-link"></span></a>조합 최적화</h3>
<p>TSP와 같이 주어진 항목들의 조합으로 해가 표현되는 최적화 문제로, 이 경우에는 경로의 길이를 최소화 하는 문제이다.</p>
<p><img src="/posts/mid_02/231022-005505.png" alt="231022-005505"/></p>
<p>이를 달성하기 위해 생물의 진화를 모방한 집단 기반 확률적 탐색 기법인 <code>유전 알고리즘</code>을 사용하기도 한다.</p>
<p>개체는 염색체로 표현되며 다음과 같이 기술된다.</p>
<p><img src="/posts/mid_02/231022-005704.png" alt="231022-005704"/></p>
<p>이런 염색체들의 집합을 <code>모집단</code>이라고 하는데, 이런 모집단(후보해)가 문제의 해로서 적합한 정도를 <code>적합도 함수</code>가 판단하게 되고, 적합하다면 최적 개체로서 알고리즘이 종료되지만, 적합하지 않다면 <strong>진화의 과정</strong>을 거치게 된다.</p>
<p>모집단이 진화를 할 때는 우선 <code>부모 모집단</code> 중 개체를 선택하게 되는데, <strong>가능한 높은 적합도의 개체가 선택되도록 확률을 높게</strong> 조정한다.<br/>
<!-- -->자연선택과 같이 <strong>랜덤</strong>한 요소가 있어야 하기에 반드시 적합한 녀석이 선택되지는 않는다.</p>
<p>이후에는 선택된 부모 개체가 <code>유전 연산</code>을 거쳐 자식 개체를 양산하게 되는데, 유전 연산에는 다음과 같은 연산을 고려할 수 있다.</p>
<p><img src="/posts/mid_02/231022-010201.png" alt="231022-010201"/></p>
<p>이후에는 생성된 여러 자식 개체를 이용해서 <code>세대를 교체</code>하게 되는데, <strong>최대한 많은 우수한 계체가 다음 세대에 유지</strong>될 수 있도록 <code>엘리트주의</code>를 적용한다.</p>
<h3 id="목적-최적화"><a class="anchor" href="#목적-최적화"><span class="icon icon-link"></span></a>목적 최적화</h3>
<p>어떤 목적 함수(Objective function)가 있을 때, 이 함수를 최대로 하거나 최소로 하는 변수 값을 찾는 최적화 문제이다.</p>
<p><img src="/posts/mid_02/231022-010440.png" alt="231022-010440"/></p>
<p><code>최소 평균제곱법</code>을 사용해서 회귀(Regression) 문제의 최적함수를 찾거나,</p>
<p><img src="/posts/mid_02/231022-010602.png" alt="231022-010602"/></p>
<p>함수의 최소값 위치를 찾는 문제에서 <code>경사 하강법</code>과 같은 방법을 사용할 수 있다.</p></div><div class="w-72 hidden h-fit max-h-[calc(100vh-10rem)] lg:flex flex-col overflow-x-hidden overflow-y-scroll scrollbar-hide rounded-xl transition-all sticky top-32 bg-gradient-to-br from-blue-400 to-blue-950"><div class=""><p id="toc-header" class="py-3 font-extrabold leading-6 bg-black bg-opacity-20 text-white">🫧 한 눈에 보기</p><ul id="toc-content" class="px-4 pb-2 mt-2 flex flex-col items-start justify-start text-sm text-start"><li><a href="#게임-트리" class="group block py-1  text-white hover:text-blue-200 hover:drop-shadow-base-bold">게임 트리</a></li><li class="ml-4"><a href="#mini-max-algorithm" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>Mini-max Algorithm</a></li><li class="ml-4"><a href="#몬테카를로-트리-탐색-기법-monte-carlo-simulation" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)</a></li><li><a href="#제약조건-만족-문제" class="group block py-1  text-white hover:text-blue-200 hover:drop-shadow-base-bold">제약조건 만족 문제</a></li><li class="ml-4"><a href="#백-트래킹-탐색-backtracking-search" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>백 트래킹 탐색 (Backtracking search)</a></li><li class="ml-4"><a href="#제약조건-전파-constraint-propagation" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>제약조건 전파 (Constraint propagation)</a></li><li><a href="#최적화" class="group block py-1  text-white hover:text-blue-200 hover:drop-shadow-base-bold">최적화</a></li><li class="ml-4"><a href="#조합-최적화" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>조합 최적화</a></li><li class="ml-4"><a href="#목적-최적화" class="group flex items-start py-[2px] text-white hover:text-blue-200 hover:drop-shadow-base"><svg width="3" height="24" viewBox="0 -9 3 24" class="mr-2 overflow-visible text-white"><path d="M0 0L3 3L0 6" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg>목적 최적화</a></li></ul></div></div></section><footer class="w-full flex flex-col mt-10"><span class="text-blue-400 italic text-start">2023-10-21 / 22:53<!-- --> 에 작성을 시작했어요.</span><div class="w-full flex items-start mt-5 mb-10 space-x-5"><span>Tag</span><ul class="w-full flex list-none m-0 flex-wrap gap-1"><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Mini-Max algorithm</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Alpha-Beta prunning</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Monte Carlo</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Backtracking search</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Constraint propagation</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Genetic algorithm</li><li class="bg-gradient-to-br from-blue-500 to-blue-400 px-3 text-white rounded-md shadow-md whitespace-nowrap"># <!-- -->Regression</li></ul></div><div class="flex flex-col items-center mb-5"><div class="w-full bg-gradient-to-br from-blue-400 to-blue-950 mt-5 rounded-md overflow-hidden"><h3 class="bg-black bg-opacity-50 px-1 py-3"><span class="bg-gradient-to-br from-blue-600 to-blue-400 bg-clip-text text-transparent font-bold drop-shadow">대학 - 인공지능</span><span class="text-white">의 다른 글</span></h3><ol class="w-full p-1 space-y-1"><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/final_05">자연어 처리</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/final_04">TensorFlow</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/final_03">딥러닝 &amp; CNN</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/final_02">신경망</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/final_01">결정 트리 &amp; 단순 베이즈 분류기</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_08">기계학습 - 비지도 &amp; 반지도학습</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_07">기계학습 - 지도학습</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_06">규칙 기반 시스템</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_05">불확실한 지식 표현</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_04">명제 논리 &amp; 술어 논리</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_03">프레임 &amp; 의미망 &amp; 스크립트</a></li><li class="w-full bg-black bg-opacity-20 rounded-md"><a class="w-full flex justify-center text-white before:content-[&#x27;🫧&#x27;] before:mr-2 after:content-[&#x27;🫧&#x27;] after:ml-2" href="/blog/univ_ai/mid_02">게임에서의 탐색 및 최적화</a></li><li class="w-full "><a class="w-full flex justify-center text-white " href="/blog/univ_ai/mid_01">상태공간 &amp; 탐색</a></li></ol></div></div><section class="w-full self-center"></section></footer></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"게임에서의 탐색 및 최적화","description":"게임 트리를 탐색하는 기법과 최적화에 대해 알아봅니다.","icon":"","image":"","tags":["Mini-Max algorithm","Alpha-Beta prunning","Monte Carlo","Backtracking search","Constraint propagation","Genetic algorithm","Regression"],"draft":false,"date":"2023-10-21 / 22:53","content":"\n## 게임 트리\n\n`상대가 있는 게임`에서 자신과 상대방의 가능한 게임 상태를 나타낸 트리.\n자신의 턴인지, 상대의 턴인지에 따라 탐색하는 방식이 다르게 적용됨.\n(나에겐 유리하게, 상대에겐 불리하게)\n\n정해진 시간 내에 최대한 많은 수를 보는 것이 유리하기 때문에 탐색 효율을 높이는 것이 중요하다.\n\n### Mini-max Algorithm\n\n특이하게 단말 노드로부터 위로 올라가면서 최소-최대 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 값을 선택하는 방법이다.\n\n자신의 턴인 Max 노드에서는 자신에게 유리한 값을 선택하고,\n상대의 턴인 Min 노드에서는 상대에게 불리한 값을 선택하는 방식을 취한다.\n\n![231021-230224](/posts/mid_02/231021-230224.png)\n\n하지만 트리가 넓을 수록 모든 상태공간을 탐색하는건 시간상 너무 오래 걸리기 때문에 최적화 기법이 들어가야 한다.\n바로 **$\\alpha - \\beta$ 가지치기(prunning)** 기법이다.\n\n검토해 볼 필요가 없는 부분을 탐색하지 않도록 하는 기법인데, 어떻게 해야 검토할 필요가 없다는 걸 알 수 있을까?\n\n깊이 우선 탐색(DFS)로 제한 깊이까지 탐색을 하면서 Min, Max 노드의 $\\alpha$, $\\beta$값을 업데이트 하는데, 각 $\\alpha$, $\\beta$값은 다음과 같은 값을 저장한다.\n\n- $\\alpha$\n  Max 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최댓값을 저장함\n\n- $\\beta$\n  Min 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최솟값을 저장함\n\n이 때, 탐색 후 값을 업데이트 하다가 **$\\alpha \\geq \\beta$** 되는 순간이 오는데, 그 때부터 나머지 자식노드는 탐색할 필요가 없어진다.\n그 이유는, 상한선($\\alpha$)과 하한선($\\beta$)이 정해질 때, 그 부모노드의 상한선과 하한선을 넘지 못하면 부모노드를 업데이트 할 수 없기에, 업데이트를 할 가능성이 없다면 가지치기를 해버리는 것이다.\n\n알고리즘의 이해가 안된다면 아래 영상을 참고하면 좋을 거 같다.\n\n\u003cYT id=\"_i-lZcbWkps\" /\u003e\n\n속성으로 빠르게 탐색하고 싶다면 이런 방식으로 탐색해도 된다.\n\n\u003cYT id=\"6qN5ReC2SUA\" /\u003e\n\n빠르게 업데이트 가능한 조건을 적어놓고, 그 조건이 업데이트가 절대로 불가능하다면 나머지 노드를 가지치기 하는 방식이다.\n\n### 몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)\n\n![231022-003000](/posts/mid_02/231022-003000.png)\n\n탐색 공간을 무작위 표본추출을 하면서 탐색 트리를 확장하여 가장 좋아보이는 것을 선택하는 휴리스틱 탐색 방법으로,\n시간이 허용되는 동안 위의 4단계를 반복하여 시뮬레이션 및 트리를 확장한다.\n\n1. 선택\n  선택은 **트리 정책**을 적용하여 선택한다.\n  정책은 개발자 마음대로 정하는 거지만, 보통 승률과 노드 방문횟수를 고려하여 선택한다.\n  일반적으로 `승률이 높으며`, `방문횟수가 적은` 노드에 우선권을 부여한다 (UCB, Upper Confidence Bound 정책).\n\n2. 확장\n  단말 노드에서 트리 정책에 따라 노드를 추가한다.\n\n3. 시뮬레이션\n  기본 정책에 의한 `몬테카를로 시뮬레이션`을 적용한다.\n  무작위 선택, 또는 약간 똑똑한 방법으로 게임이 끝날 때 까지 진행한다.\n\n  \u003ctip\u003e\n  `몬테카를로 시뮬레이션`\n  \u003cbr /\u003e\n  특정 확률 분포로 부터 무작위 표본(또는 약간 똑똑한 방법으로)을 생성하고, 이 표본에 따라 행동을 하는 과정을 반복하여 결과를 확인하고 이 과정을 반복해 최정 결정을 하는 것.\n  \u003cbr /\u003e\n  특정 상태의 유불리를 상태판단함수로 판단하는 것이 아닌, 시뮬레이션으로 판단하게 된다.\n  \u003c/tip\u003e\n\n4. 역전파\n  게임의 결과를 단말 노드에서 루트 노드까지 올라가면서 반영한다.\n\n---\n\n## 제약조건 만족 문제\n\n주어진 제약조건을 만족하는 조합 해(combination solution)을 찾는 문제로 N-Queens problem과 같은 문제가 이에 해당한다.\n\n### 백 트래킹 탐색 (Backtracking search)\n\n깊이 우선 탐색(DFS)을 하는 것처럼 변수에 허용되는 값을 하나씩 대입해보고, 가능한 모든 값을 대입했는데도 만족하는 것이 없으면 이전 단계로 돌아가서 이전 단계의 변수에 다른 값을 대입하는 전형적인 백 트래킹 방식이다.\n\n### 제약조건 전파 (Constraint propagation)\n\n인접 변수 간의 제약 조건에 따라 각 변수에 허용될 수 없는 값들을 제거하는 방식으로, 이름 그대로 주변에 제약조건을 전파하여 선택 가능한 가지수를 줄여가는 방식이다.\n\n![231022-004410](/posts/mid_02/231022-004410.png)\n\nA에 1을 선택하는 순간 B\\~D에 각각 제약사항이 전파되어 B\\~D에서 선택할 수 있는 가지수가 제한된다.\n여기서 B가 3을 선택하는 순간 C, D에 각각 제약사항이 또 전파되는데, 이 때 C는 더이상 아무것도 선택할 수 없기에 이전 스탭에서 다른 제약사항을 걸어야 한다.\n\n---\n\n## 최적화\n\n여러가지 가능, 혀용되는 값들 중에서 주어진 기준을 가장 잘 만족하는 것을 선택하는 것으로, 크게 `조합 최적화`와 `함수 최적화`로 나뉜다.\n\n### 조합 최적화\n\nTSP와 같이 주어진 항목들의 조합으로 해가 표현되는 최적화 문제로, 이 경우에는 경로의 길이를 최소화 하는 문제이다.\n\n![231022-005505](/posts/mid_02/231022-005505.png)\n\n이를 달성하기 위해 생물의 진화를 모방한 집단 기반 확률적 탐색 기법인 `유전 알고리즘`을 사용하기도 한다.\n\n개체는 염색체로 표현되며 다음과 같이 기술된다.\n\n![231022-005704](/posts/mid_02/231022-005704.png)\n\n이런 염색체들의 집합을 `모집단`이라고 하는데, 이런 모집단(후보해)가 문제의 해로서 적합한 정도를 `적합도 함수`가 판단하게 되고, 적합하다면 최적 개체로서 알고리즘이 종료되지만, 적합하지 않다면 **진화의 과정**을 거치게 된다.\n\n모집단이 진화를 할 때는 우선 `부모 모집단` 중 개체를 선택하게 되는데, **가능한 높은 적합도의 개체가 선택되도록 확률을 높게** 조정한다.\n자연선택과 같이 **랜덤**한 요소가 있어야 하기에 반드시 적합한 녀석이 선택되지는 않는다.\n\n이후에는 선택된 부모 개체가 `유전 연산`을 거쳐 자식 개체를 양산하게 되는데, 유전 연산에는 다음과 같은 연산을 고려할 수 있다.\n\n![231022-010201](/posts/mid_02/231022-010201.png)\n\n이후에는 생성된 여러 자식 개체를 이용해서 `세대를 교체`하게 되는데, **최대한 많은 우수한 계체가 다음 세대에 유지**될 수 있도록 `엘리트주의`를 적용한다.\n\n### 목적 최적화\n\n어떤 목적 함수(Objective function)가 있을 때, 이 함수를 최대로 하거나 최소로 하는 변수 값을 찾는 최적화 문제이다.\n\n![231022-010440](/posts/mid_02/231022-010440.png)\n\n`최소 평균제곱법`을 사용해서 회귀(Regression) 문제의 최적함수를 찾거나,\n\n![231022-010602](/posts/mid_02/231022-010602.png)\n\n함수의 최소값 위치를 찾는 문제에서 `경사 하강법`과 같은 방법을 사용할 수 있다.","slug":"univ_ai/mid_02","readingMinutes":11,"wordCount":724},"posts":[{"title":"자연어 처리","description":"자연어 처리의 과정에 대해 간략히 알아봅니다.","icon":"","image":"","tags":[],"draft":false,"date":"2023-12-09 / 22:25","content":"\n## 분석 단계\n\n![231209-224151](/posts/final_05/231209-224151.png)\n\n### 형태소 분석\n\n입력된 문자열을 분석하여 형태소 단위로 분석합니다.\n형태소 분석은 다음과 같은 목적 활용될 수 있습니다.\n\n- 맞춤법, 철자 교정\n- 단어의 품사 분석\n- 단어의 의미 추정\n- 검색엔진 색인 구성\n\n형태소를 분석하고 나서는 품사를 태깅합니다.\n태깅을 할 때는 문장의 구성 원리 등을 이용한 규칙 기반 태깅 방법과, 기계학습 기반 태깅이나, 통계적 기계학습 알고리즘을 사용할 수 있습니다.\n\n이후에는 개체명을 인식합니다.\n정보를 검색하거나, 질의응답에서 중요한 역할을 하는 고유명사와 같은 개체명을 인식하는 겁니다.\n인명, 지명, 시간, 날짜, 화폐 등이 이에 해당합니다.\n개체명을 인식할 때는 사전을 사용하거나, 규칙을 만들거나, 기계학습 기반의 분류기를 사용합니다.\n\n### 구문 분석\n\n구문에 따라 주어진 문장에서 단어들의 역할을 파악하여 문장을 계층적인 트리 구조로 변환하는 작업입니다.\n이 역시 규칙 기반 구문 분석방법과 기계학습 기반 구문 분석방법이 있습니다.\n\n하지만, 구문 분석시에는 아래와 같은 문제점이 있을 수 있습니다.\n\n- 구조적 중의성\n  하나의 문장이 다수의 구조로 해석될 수 있음.\n- 어휘적 중의성\n  하나의 단어가 여러 품사로 사용될 때, 다수의 구조로 해석될 수 있음.\n\n규칙 기반 구분 분석에서는 파싱 방식을 자주 사용하는데, 파싱 방식에는 아래와 같은 방식이 있습니다.\n\n- 확장 전이망 기반 파싱\n- 차트 파싱 (CKY 파싱 알고리즘)\n\n기계학습 기반 구문 분석에서는 아래와 같은 모델이 사용됩니다.\n\n- SVM\n- 조건부 랜덤 필드(CRF) 모델\n- 딥러닝 신경망\n\n### 의미 분석\n\n형태소, 구분 분석 결과를 해석하여 문장이 가진 의미를 파악합니다.\n이를 위해 담화가 이루어지는 상황에 대한 world model과 상식에 대한 지식이 필요합니다.\n\n이를 위해 단어를 수치화 해야 하는데, ont-hot vector 또는 Word2Vec(word embedding)을 사용합니다.\n두 방식 모두 단어를 좌표상에 하나의 위치벡터로 수치화 합니다.\n\n- one-hot vector\n  단어 위치에만 1, 나머지는 0으로 설정된 벡터입니다.\n  학습에는 편리하지만, 이 방식은 단어간의 유사도를 계산하기가 어렵습니다.\n\n- Word2Vec\n  단어의 의미를 충분히 잘 나타내도록 단어를 공간상의 실수 벡터로 표현합니다.\n  유사한 의미의 단어는 좌표공간 상에서 근처에 위치하게 되기 때문에 유사도를 판단할 때 유용합니다.\n\n이렇게 단어를 벡터화(수치화) 하고나면, 단어를 유의미하게 배치하기 위한 모델을 구성해야 합니다.\none-hot vector로 수치화된 단어는 아래와 같은 모델에서 사용됩니다.\n\n- CBOW\n\n    ![231209-230325](/posts/final_05/231209-230325.png)\n    Continuous Bag-of-Words 모델은 V차원의 one-hot 벡터로 표현된 단어를 N차원의 실수 벡터로 바꾸는 역할을 수행합니다.\n    입력에 주변 단어들이 주어질 때, 출력에서 해당 단어가 나타날 확률이 높아지도록 학습합니다.\n    e.g. 빈칸 채우기\n\n- Skip-gram\n\n    ![231209-230425](/posts/final_05/231209-230425.png)\n    CBOW 모델과 대칭적인 구조를 갖습니다.\n    입력에 학습 대상이 되는 단어가 주어질 때, 출력에서 해당 단어의 주위 단어들이 나타날 확률이 높아지도록 학습합니다.\n    e.g. 문장 생성\n\nWord2Vec로 수치화된 단어는 아래와 같은 분야에서 사용됩니다.\n\n- 유의어, 어근 비교, 시제 등 한 정보 추출 또는 분석\n- 품사 태깅, 의미 분석, 관계 추출, 단위 의미 식별 등\n- 기계 번역, 영상 주석달기 등","slug":"univ_ai/final_05","readingMinutes":6,"wordCount":401},{"title":"TensorFlow","description":"딥러닝 프레임워크 텐서플로우에 대해 알아봅니다.","icon":"","image":"","tags":["Tensor"],"draft":false,"date":"2023-12-09 / 18:17","content":"\n## Tensor\n\n텐서플로우에서 사용하는 기본 자료형으로 다차원 배열이다.\n텐서는 rank, shape, type의 세가지 속성을 갖는다.\n\n- rank\n\n    ![231209-201955](/posts/final_04/231209-201955.png)\n    텐서의 차원수로 rank k는 k차원 배열이다.\n\n- shape\n\n    ![231209-202047](/posts/final_04/231209-202047.png)\n    텐서의 구조로, 각 축에 텐서의 원소 개수를 알려준다.\n\n- type\n  텐서의 구성원소의 자료형을 알려준다.\n\n\u003ctip\u003e\n  `축(axis)`\n  \u003cbr /\u003e\n  대괄호의 가장 바깥부터 0, 1, 2 축이 된다.\n\u003c/tip\u003e\n\n## Flow\n\n텐서를 데이터 플로우 그래프를 이용하여 계산 과정과 모델을 표현하게 된다.\n\n- Op(eration)\n  하나 이상의 텐서를 받아 계산을 수행하고 결과를 하나 이상의 텐서로 변환\n\n- Session\n  그래프를 실행하기 위한 객체(세션)\n\n- Variables\n\n    그래프 실행 시 파라미터를 저장하고 갱신하기 위해 사용\n    ```python:.py\n    W = tf.Variable(tf.randon_normal([4, 1]), name=\"weight\")\n    b = tf.Variable(tf.randon_normal([1]), name=\"bias\")\n    ```\n\n- Placeholder\n\n    데이터 플로우 그래프 실행 시 데이터(텐서)를 전달하기 위해 사용\n    ```python:.py\n    x = tf.placeholder(tf.float32)\n    y = tf.placeholder(tf.float32)\n    z = tf.multiply(x, y)\n    sess.run(z, feed_dict=[x: 3, y: 4])\n    ```\n\n---\n\n## 텐서 변환 연산\n\n### reshape\n\n텐서의 원소를 새로운 shape에 맞게 배치합니다.\n\n\u003e a = [[[1,2,3,4], [5,6,7,8]], [[9,10,11,12], [13, 14, 15, 16]], [[17,18,19,20], [21,22,23,24]]]\n\u003e tf.shape(a) \u0026rarr; [3, 2, 4]\n\u003e tf.reshpae(a, [3, 8])\n\u003e \u0026rarr; [[1,2,3,4,5,6,7,8], [9,10,11,12,13,14,15,16], [17,18,19,20,21,22,23,24]]\n\n### squeeze\n\n텐서에서 크기가 1인 축을 제거합니다.\n\n\u003e a = [**[**[1,2]**]**, **[**[3,4]**]**, **[**[5,6]**]**]\n\u003e tf.shape(a) \u0026rarr; [3, 1, 2]\n\u003e tf.squeeze(a)\n\u003e \u0026rarr; [[1,2], [3,4], [5,6]]\n\n### expand_dims\n\n지정한 축 위치에 차원을 하나 추가합니다.\n\n\u003e tf.expands_dims([[1,2,3], [4,5,6]], 0)\n\u003e \u0026rarr; **[**[[1,2,3], [4,5,6]]**]**\n\u003e tf.expands_dims([[1,2,3], [4,5,6]], 1)\n\u003e \u0026rarr; [**[**[1,2,3]**]**, **[**[4,5,6]**]**]\n\n### slice\n\n텐서에서 일부분을 선택합니다.\n**slice(텐서, [축i 시작위치], [축i의 추출길이])**\n\n\u003e a = [[1,2,3,4,5,6,7], [8,9,10,11,12,13,14], [15,16,17,18,19,20,21]]\n\u003e tf.slice(a, [0,2], [2,3])\n\u003e \u0026rarr; [[3,4,5], [10,11,12]]\n\n### split\n\n지정된 축을 분할개수로 분리합니다.\n**spilt(텐서, 분할개수, 축)**\n\n\u003e a = [[1,2,3,4], [5,6,7,8], [9,10,11,12], [13,14,15,16]]\n\u003e tf.split(a, 2, 0)\n\u003e \u0026rarr; [[[1,2,3,4], [5,6,7,8]], [[9,10,11,12], [13,14,15,16]]]\n\u003e tf.split(a, 2, 1)\n\u003e \u0026rarr; [[[1,2], [5,6], [9,10], [13,14]], [[3,4], [7,8], [11,12], [15,16]]]\n\n### concat\n\n지정된 축 방향으로 두 텐서를 이어 붙힙니다.\n\n\u003e a = [[1,2], [3,4]]\n\u003e b = [[5,6], [7,8]]\n\u003e tf.concat([a, b], 0)\n\u003e \u0026rarr; [[1,2], [3,4], [5,6], [7,8]]\n\u003e tf.concat([a, b], 1)\n\u003e \u0026rarr; [[1,2,5,6], [3,4,7,8]]\n\n### reverse\n\n지정된 축을 기준으로 원소를 역순으로 배열합니다.\n\n\u003e a = [[1,2,3], [4,5,6]]\n\u003e tf.reverse(a, [0])\n\u003e \u0026rarr; [[4,5,6], [1,2,3]]\n\u003e tf.reverse(a, [1])\n\u003e \u0026rarr; [[3,2,1], [6,5,4]]\n\u003e tf.reverse(a, [0, 1])\n\u003e \u0026rarr; [[6,5,4], [3,2,1]]\n\n### transpose\n\n지정된 축의 순서로 텐서를 transpose 합니다.\n**transpose(텐서, perm=[축])**\n(perm을 지정 안하면 [0, 1] 로 간주함)\n\n\u003e a = [[1,2,3], [4,5,6]]\n\u003e tf.transpose(a)\n\u003e \u0026rarr; [[1,4], [2,5], [3,6]]\n\u003e b = [[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]]\n\u003e tf.transpose(b, [0,2,1])\n\u003e \u0026rarr; [[[1,4], [2,5], [3,6]], [[7,10], [8,11], [9,12]]]\n\n### gather\n\n지정된 index의 원소들로 이루어진 텐서를 생성합니다.\n**gather(텐서, [index])**\n\n\u003e tf.gather([1,3,5,7,9,0,2,4,6,8], [2,5,2,5])\n\u003e \u0026rarr; [5,0,5,0]\n\u003e tf.gather([[1,2,3,4,5,6], [7,8,9,10,11,12]], [0,1])\n\u003e \u0026rarr; [[1,2,3,4,5,6], [7,8,9,10,11,12]]\n\u003e tf.gather([[1,2,3,4,5,6], [7,8,9,10,11,12]], [[0,0], [1,1]])\n\u003e \u0026rarr; [[[1,2,3,4,5,6], [1,2,3,4,5,6]], [[7,8,9,10,11,12], [7,8,9,10,11,12]]]\n\n### ont_hot\n\n정수값을 one-hot 벡터로 변환합니다.\n\n\u003e tf.ont_hot([0,1,2], depth=3)\n\u003e [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n\u003e tf.ont_hot([0,1,2], depth=4)\n\u003e [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0]]\n\n---\n\n## 기타\n\n### 텐서 축약 연산\n\n![231209-222217](/posts/final_04/231209-222217.png)\n\n### 텐서 행렬 연산\n\n![231209-222315](/posts/final_04/231209-222315.png)\n\n","slug":"univ_ai/final_04","readingMinutes":4,"wordCount":492},{"title":"딥러닝 \u0026 CNN","description":"딥러닝 및 CNN 방식의 종류와 모델들을 알아봅니다.","icon":"","image":"","tags":["Deep Learning","Convolutional Neural Network","CNN Models"],"draft":false,"date":"2023-12-09 / 16:42","content":"\n## 딥러닝\n\n일반적인 다수의 퍼셉트론을 이용해서 은닉층을 여럿 두었던 기존 신경망과 거의 유사하지만, 그 은닉층의 개수가 엄청 많은 신경망을 딥러닝 신경망이라고 합니다.\n\n원시 신경망은 은닉층의 개수가 적었기에, 사람이 직접 특징을 추출해서 만든 특징 벡터를 이용해 학습을 시켰던 것에 반해,\n딥러닝 신경망은 데이터 그 자체를 입력으로 주고, 특징 추출과 학습을 함께 수행할 수 있습니다.\n즉, 스스로 데이터로부터 유의미한 특징을 추출하고 학습하기 때문에 성능이 우수합니다.\n\n### 기울기 소멸 문제\n\n단, 딥러닝시 문제가 있습니다.\n컴퓨팅 파워가 많이 필요하단 것은 둘 째 치고, 학습하는 과정에서 역전파를 할 때, 역전파 하는 과정에서 전파될수록 기울기(gradient)가 점점 줄어들다가 소멸하는 문제가 있습니다.\n\n기울기 소멸 문제가 발생하는 이유는 sigmoid, typertangent와 같은 활성함수를 사용하기 때문에 발생하는 것인데, 이런 활성함수의 특징이 있습니다.\n바로, 0에서 멀어질수록 도함수(기울기)의 값이 0에 가까워진다는 점입니다.\n\n따라서 아무리 멀어져도 기울기가 0으로 수렴하지 않도록 ReLU 함수나 ReLU 파생 함수를 사용하곤 합니다.\n\n![231209-165142](/posts/final_03/231209-165142.png)\n\n### 가중치 초기화 문제\n\n신경망을 학습하는 과정에서 경사하강법을 사용한다고 했었는데, 경사하강법의 문제가 있습니다.\n바로 국소 최적해에 빠질 수 있다는 것입니다.\ngradient의 반대 방향으로 이동하는 과정에서 더이상 움직이지 않는 지점까지 내려왔는데, 알고보니 그 지점보다 더 낮은 지점이 존재하는 것이죠.\n\n즉, 학습에 있어, 초기에 가중치를 어떻게 초기화하느냐에 따라 학습 방향이 변하게 될 수 있다는 뜻입니다.\n\n보통은 초기값으로 0에 가까운 무작위 값을 넣곤하는데, 균등 분포, Xavier 초기화, He 초기화 방법 등이 있습니다.\n\n### 과적합 문제\n\n학습을 너무 완벽하게 시켜도 문제입니다.\n\n![231209-170008](/posts/final_03/231209-170008.png)\n\n해당 모델은 학습 데이터를 완벽하게 분류할 수 있을 뿐, 테스트데이터에 대해서는 좋지 못한 성능을 보일 수 있기 때문입니다.\n\n따라서 여러 과적합 완화 기법이 있습니다.\n\n- 규제화 기법\n\n    오차함수에 error 뿐 만 아니라 모델 복잡도도 평가요소로 사용하는 방법입니다.\n\n    **오차함수 = 오차 항 + $\\alpha$ 모델 복잡도 항**\n\n    모델 복잡도는 가중치(weight)를 이용하여 정의할 수 있으며 아래와 같이 사용할 수 있습니다.\n\n    - L1-norm: $\\sum_{i=1}^{n}|w_i|$\n    - L2-norm: $\\sum_{i=1}^{n}w_i^2$\n\n- 드롭아웃 기법\n\n    일정 확률로 노드들을 무작위로 선택해 선택된 노드 앞뒤로 연결된 가중치 연결선은 없는 것으로 간주하고 학습하는 기법입니다.\n\n    ![231209-170524](/posts/final_03/231209-170524.png)\n\n    미니배치(mini-batch)나 학습주기(epoch)마다 드롭아웃할 노드를 선택하는데, 모든 노드는 한 번 이상은 특정 주기에 속해 학습되어야 합니다.\n\n    \u003ctip\u003e\n      `미니배치(mini-batch)`\n      \u003cbr /\u003e\n      전체 학습 데이터를 일정 크기의 데이터로 나누어 놓은 것으로, 학습 데이터가 큰 경우에 사용하는 것이 좋습니다.\n      단, 그레디언트를 계산할 때는 매 데이터마나 역전파해서 업데이트 하는 것이 아닌, 일정 수 이상의 데이터가 들어올 때 마다 평균을 계산해서 한 번에 업데이트 해야합니다.\n      \u003cbr /\u003e\n      미니배치의 장점은 데이터에 포함된 오류에 대해 둔감하게 학습할 수 있기에 과적함 문제 완화에 도움이 됩니다.\n    \u003c/tip\u003e\n  \n- 배치 정규화\n\n    신경망의 각 층에서 미니배치의 각 데이터의 가중치 연산 결과의 분포를 정규화 하는 것으로, 간단하게 말하면 출력을 \\[-1, 1\\] 범위로 스케일링 하는 것입니다.\n\n    이게 도움이 되는 이유는 내부 공변량 이동 문제를 완화할 수 있기 때문인데요, 간단하게 설명하면 학습에 따라 가중치가 변하면 같은 학습 데이터에 대해 출력이 변하는 문제입니다.\n\n    하지만, 배치 정규화를 통해 출력을 정규화하면 같은 학습 데이터에 대해 시차가 있더라도 비슷한 출력을 내보낼 수 있게 되어 학습 효율이 올라갑니다.\n\n    ![231209-171350](/posts/final_03/231209-171350.png)\n\n    연산 결과를 활성화 함수에 통과시키기 전에 배치 정규화 블록을 삽입하여 구현합니다.\n\n---\n\n## 컨볼루전 신경망 (CNN)\n\nConvolution이란, 신경망에 컨볼루전을 처리하는 층이 추가된 딥러닝 신경망으로, 해당 컨볼루턴 층에서는 색상, 밝기, 에지 등등 특정 영역에 대한 특징을 추출하는 역할을 진행합니다.\n(컴퓨터 비전의 그 컨볼루전임)\n\n![231209-171707](/posts/final_03/231209-171707.png)\n\n이런 컨볼루전은 여러개 두어 각 영역 특징들을 추출하고, 해당 특징을 이용해 딥러닝 신경망의 새로운 입력으로 사용해 의미있는 정보로 변환되게 됩니다.\n\n### 컨볼루전\n\n![231209-171759](/posts/final_03/231209-171759.png)\n\n컴퓨터 비전과 비슷하게 일정 영역의 값에 가중치를 적용하여 하나의 값을 얻는 과정입니다.\n단, 여기에 threshold에 해당하는 bias 도 더해진다는 차이점이 있습니다.\n\n$$\ny_{11} = w_{11}x_{11} + w_{12}x_{12} + ... + w_{33}x_{33} + w_0 (bias)\n$$\n\n\n![231209-172107](/posts/final_03/231209-172107.png)\n\n컨볼루전시 padding과 stride 요소에 따라 연산이 조금 달라지게 되는데요,\n피연산 배열을 확장하는 것을 padding, 커널의 이동거리를 stride라고 합니다.\n\n### 특징지도\n\n컨볼루전 필터의 적용 결과로 만들어지는 2차원 행렬(N차원 배열)을 feature map 이라고 합니다.\n단순히 컨볼루전의 연산 결과라고 생각해도 됩니다.\n\n![231209-172428](/posts/final_03/231209-172428.png)\n\nk개의 커널을 컨볼루전하면 k개의 2차원 특징지도가 만들어집니다.\n커널은 RGB, 모서리, 경계선, 주파수 등등 필요한 정보를 추출할 수 있는 커널을 사용할 수 있습니다.\n\n### 풀링\n\n일정 크기의 블록을 통합하여 하나의 대푯값으로 대체하는 연산을 pooling 이라고 합니다.\n특징지도의 크기를 축소함으로서 다음 단계에서 사용할 메모리 크기와 연산량을 감소하는데 사용되며,\n특정 영역내의 특징을 결합하거나, 위치변화에 둔감한 특정을 선택하는 효과를 얻을 수 있습니다.\n\n풀링 방식의 종류에 대해 알아봅시다.\n\n- 최댓값 풀링\n\n    ![231209-172746](/posts/final_03/231209-172746.png)\n\n    지정된 블록 내의 원소 중에서 최대값을 대푯값으로 선택하는 풀링입니다.\n\n- 평균값 풀링\n\n    ![231209-172815](/posts/final_03/231209-172815.png)\n\n    지정된 블록 내의 원소의 평균값을 대푯값으로 선택하는 풀링입니다.\n\n- 확률적 풀링\n\n    ![231209-172848](/posts/final_03/231209-172848.png)\n\n    지정된 블록 내의 원소의 값의 크기에 비례하는 확률로 선택하는 풀링힙니다.\n    **학습시에는 확률적으로 학습**하기에 랜덤성이 부여되는 장점이 있고,\n    **추론시에는 확률에 가중치를 둔 평균**으로 구하는 방식으로 동작합니다.\n\n### CNN 구조\n\n특징을 추출하는 컨볼루전 부분과 추출된 특징을 사용하여 분류, 회귀하는 다층 퍼셉트론 부분으로 구분됩니다.\n\n컨볼루전 부분은 보통 아래의 층드로 구성된 블록들을 여럿 반복하여 배치합니다.\n\n- Conv: 컨볼루전 연산\n- ReLU: 활성화 함수\n- Pool: 풀링\n\nReLU, Pool은 둘 다 쓰거나 둘 중 하나만 사용할 수도 있습니다.\n\n다층 퍼셉트론 부분은 전 방향 연결되어있기에 FC(Fully Connected) 로 표현하며, 마지막 층은 출력을 정규화하기 위해 SM(SoftMax) 층을 둡니다.\n\n이에 대한 예시는 다음과 같습니다.\n\n![231209-173733](/posts/final_03/231209-173733.png)\n![231209-173744](/posts/final_03/231209-173744.png)\n\nPool을 제외하고는 가중치 연산이 필요합니다.\n노드는 Conv에서 많은 경향이 있고, 가중치는 FC에서 많은 경향이 있습니다.\n\n### CNN 학습\n\nCNN의 학습 방법은 여러 방법이 있지만, 제가 수식을 이해못한 관계로(...) 종류와 특징만 기술하도록 하겠습니다.\n\n- 경사 하강법\n  그레디언트의 반대방향으로 학습률($\\eta$) 만큼의 보폭으로 이동하는 방식입니다.\n\n- 모멘텀을 고려한 경사 하강법\n\n    ![231209-174536](/posts/final_03/231209-174536.png)\n\n    이전 그레디언트의 누적값을 반영하여 이동하는 방식입니다.\n\n- NAG\n\n    ![231209-174626](/posts/final_03/231209-174626.png)\n\n    직전 모멘텀으로 이동한 위치에서의 그레디언트로 이동하는 방식입니다.\n  \n- AdaGrad\n  가중치별로 별도의 학습률($\\eta$)을 적용하는 방식입니다.\n  예로 들어 x축보다 y축의 움직임이 크다면, y축에는 낮은 학습률을 적용하는 방식입니다.\n\n- AdaDelta\n  AdaGrad의 변형으로 과거 그레디언트의 영향을 점점 줄이는 방식입니다.\n\n- RMSprop\n\n- ADAM (best?)\n\n---\n\n## CNN 모델 종류\n\n전부 깊이 다뤄보지는 않고, ILSVRC 대회에서 좋은 성적을 거둔 모델 중 새로운 방식을 적용한 사례에 대해서만 알아봅시다.\n\n### LeNet\n\n![231209-175915](/posts/final_03/231209-175915.png)\n\n- 대회에서 최초로 컨볼루전을 사용\n\n### AlexNet\n\n![231209-175924](/posts/final_03/231209-175924.png)\n\n- 대회에서 최초로 ReLU 함수를 사용\n- FC층에 드롭아웃 기법 적용\n- 최댓값 풀링 사용\n\n### VGGNet\n\n![231209-175939](/posts/final_03/231209-175939.png)\n\n- 모든 컨볼루전 층에서 3by3 필터를 사용\n\n\u003ctip\u003e\n  3by3을 2번 적용하면 5by5를 적용한 효과를 낼 수 있고, 3번 적용하면 7by7을 적용한 효과를 낼 수 있습니다.\n  여기서 작은 필터를 여러번 사용하는게 큰 필터 한 번을 사용하는 것 보다 좋은 효과를 얻을 수 있었는데요,\n  그 이유는 가중치 개수가 적어지는 효과도 있고, 컨볼루전만 하면 선형 변환이라 중간에 ReLU 같은 비선형 변환을 사용해야 하는데, ReLU를 많이 사용할수록 복잡한 결정 경계를 표현할 수 있게되기 때문입니다.\n\u003c/tip\u003e\n\n### GoogleNet\n\n![231209-175950](/posts/final_03/231209-175950.png)\n\n- 인셉션 모듈 사용\n- 1by1 컨볼루전 사용\n- FC층 단 1개 사용\n- 보조 분류기 사용해 기울기 소멸 문제 완화\n\n\u003ctip\u003e\n  `인셉션 모듈`\n  \u003cbr /\u003e\n  ![231209-180142](/posts/final_03/231209-180142.png)\n  특징을 동시에 추출할 수 있습니다.\n\u003c/tip\u003e\n\n\u003ctip\u003e\n  `1by1 컨볼루전`\n  \u003cbr /\u003e\n  ![231209-180225](/posts/final_03/231209-180225.png)\n  특징지도를 압축할 수 있습니다.\n\u003c/tip\u003e\n\n### ResNet\n\n![231209-180954](/posts/final_03/231209-180954.png)\n\n- 잔차 모듈 사용\n\n\u003ctip\u003e\n  `잔차 모듈`\n  \u003cbr /\u003e\n  ![231209-180447](/posts/final_03/231209-180447.png)\n  입력값을 그대로 넘기는 과정이 추가된 모듈로 이를 이용하면 기울기 소멸 문제를 완화할 수 있습니다.\n  뿐만 아니라, 작은 변화에도 민감하며, 다양한 경로를 통해 복합적인 특징을 추출할 수도 있습니다.\n  \u003cbr /\u003e\n  ![231209-180724](/posts/final_03/231209-180724.png)\n  즉, 여러 층이 연결된 효과를 볼 수 있습니다.\n  때문에, 필요한 출력이 얻어지면 컨볼루전 층을 건너뛸 수도 있습니다.\n\u003c/tip\u003e\n\n### DenseNet\n\n![231209-180943](/posts/final_03/231209-180943.png)\n\n앞 층에서 올 수 있는 지름길 연결구성 방식이기에 연산 방식이 ResNet과 좀 다릅니다.\n\n- ResNet: Conv-배치정규화-ReLU\n- DenseNet: 배치정규화-ReLU-Conv\n\n따라서 이전 단계의 동일한 특징 정보가 진차모듈을 통해 각 단계에 전달되기 때문에 새로운 특징을 만드는데 소극적이었던 ResNet과 달리\n새로운 특징이 추출될 가능성이 높아졌습니다.\n\n![231209-181230](/posts/final_03/231209-181230.png)\n\n또한, 전이층을 두어 층이 과도하게 늘어나는 현상을 예방하고 학습 효율을 높였습니다.\n\n### DPN\n\nResNet + DenseNet 으로, DenseNet의 단점인 특징이 중복해서 추출될 수 있는 문제를 마이크로 블록을 사용하여 극복한 모델입니다.","slug":"univ_ai/final_03","readingMinutes":17,"wordCount":1180},{"title":"신경망","description":"인공지능 신경망의 구조와 원리에 대해 알아봅니다.","icon":"","image":"","tags":["Neural Network","Perceptron"],"draft":false,"date":"2023-12-08 / 23:53","content":"\n## 퍼셉트론\n\n![231209-160856](/posts/final_02/231209-160856.png)\n\n인간의 신경세포를 모방한 신경망 모델에서 하나의 신경세포에 해당하는 뉴런 유닛입니다.\n다른 퍼셉트론의 출력들을 입력으로 받아 하나의 출력을 생성하게 되는데요, 입력들의 합이 threshold를 넘으면 1, 아니면 0을 출력하게 됩니다.\n\n$$\ny = \\left\\{\\begin{matrix}\n0 \\; otherwise \\\\\n1 \\; \\sum_{i=1}^{d}w_ix_i \u003e threshold\n\\end{matrix}\\right.\n$$\n\n이 때, $\\sum_{i=1}^{d}w_ix_i \u003e threshold$ 부분을 아래와 같이 수정해봅시다.\n\n$$\n\\sum_{i=1}^{d}w_ix_i - threshold\u003e 0\n$$\n\nthreshold를 마찬가지로 하나의 입력으로 생각할 수도 있을 것입니다.\n즉, 가중치(w)가 1이고, 값(x)이 bias 라고 생각하면 아래와 같이 식이 정리됩니다.\n\n$$\ns = \\sum_{i=1}^{d}w_ix_i + b = \\sum_{i=0}^{d}w_ix_i\n$$\n\n이제 s의 값이 0보다 작으면 0을 출력하고, 0보다 크면 1을 출력하면 퍼셉트론 완성입니다.\n\n퍼셉트론을 이용해서 OR 회로를 만들어봅시다.\n\n![231209-161940](/posts/final_02/231209-161940.png)\n\n그럼 AND 회로는 만들 수 있을까요?\nbias(1)에 연결된 weight에 -0.5가 아닌 -1.5와 같은 값을 넣으면 만들 수 있습니다.\n\n그렇다면 XOR 회로는 만들 수 있을까요?\n위와 같이 퍼셉트론 1개만으로는 구현이 불가능합니다.\n하나의 퍼셉트론은 선형 분리가능 문제만 해결할 수 있기 때문입니다.\n\nXOR와 같은 선형 분리불가 문제는 2개 이상의 퍼셉트론으로 해결할 수 있습니다.\n\n### 다층 퍼셉트론\n\n여러 개의 퍼셉트론을 층 구조로 구성한 신경망 모델을 의미하며, 이를 이용하면 단일 퍼셉트론의 한계였던 선형 분리불가 문제도 해결할 수 있습니다.\n\n다층 퍼셉트론을 이용해서 XOR 회로를 만들어봅시다.\n\n![231209-162649](/posts/final_02/231209-162649.png)\n\n### 학습\n\n다층 퍼셉트론을 학습을 시킨다는 것은 입력-출력 학습데이터에 대해 출력값과 오파의 차이가 최소가 되도록 가중치(weight)를 조정하는 것을 의미합니다.\n\n이를 위해 역전파 알고리즘을 사용하는데, 역전파 알고리즘은 미분을 사용합니다.\n따라서 수식화된 퍼셉트론이 미분 가능해야 하는데, threshold(bias)보다 크다/작다로 1/0이 나뉘는 step 함수를 사용하는 경우에는 미분이 불가능합니다.\n\n![231209-162951](/posts/final_02/231209-162951.png)\n\n그렇기에 미분이 가능한 sigmoid 함수나 다른 함수를 사용하여 출력값을 결정합니다.\n\nXOR와 같은 간단한 회로는 학습이 필요없이 바로 weight를 결정할 수 있지만, 사물 인식과 같이 상상할 수 없는 회로의 경우에는 퍼셉트론 층들을 많이 두고, 학습하는 방식으로 회로를 구성하게 됩니다.\n\n![231209-163157](/posts/final_02/231209-163157.png)\n\nn개의 은닉층을 둔 n+1층 퍼셉트론을 구성하면 복잡한 회로도 만들 수 있습니다.\n단, weight을 계산하는 것은 사실상 불가능하기 때문에 학습이라는 이름의 노가다(?)를 통해 weight이 오류가 적어지는 방향으로 조정하는 것입니다.\n\n학습 데이터의 입력은 $x_i$들의 벡터로 주어지고, 출력은 $y_i$의 벡터로 주어지는데, $y_i$ 중 하나만 1이고 나머지는 0인 ont-hot 벡터로 주어지는게 일반적입니다.\n\n오류를 줄이는 방향으로 학습하기 위한 방식으로 최대경사법 또는 경사하강법이라는 태크닉이 사용됩니다.\n원리만 설명하면, 각 스탭에서의 x, y 편미분을 구합니다(gradient).\n그리고, gradient의 반대 방향으로 weight를 수정하면 에러가 작아지는 방식입니다.\n\n### 기타\n\n최종 출력시 모든 속성값에 대한 확률을 0~1로 표현하기 위해 마지막 층으로 소프트맥스 층을 두기도 합니다.\n`소프트맥스 층`은 최종 출력을 분류 확률로 변환하는 층으로 모든 퍼셉트론 출력의 합이 1이 됩니다.\n\n가중치를 사용하는 대신, 퍼셉트론이 기존 벡터와 입력 벡터의 유사도를 측정하는 방식인 `RBF망` 이라는 방식도 있습니다.","slug":"univ_ai/final_02","readingMinutes":6,"wordCount":395},{"title":"결정 트리 \u0026 단순 베이즈 분류기","description":"결정 트리의 형태, 학습 알고리즘, 회귀와 단순 베이즈 분류기에 대해 알아봅니다.","icon":"","image":"","tags":["Decision Tree","Information Gain","Information Gain Ratio","Gini Gain","Regression","Naive Bayesian Classifier"],"draft":false,"date":"2023-12-08 / 21:32","content":"\n## 결정 트리\n\n의사결정 지식을 트리의 형태로 표현한 것으로, 구성요소는 다음과 같습니다.\n\n| 구성요소 | 역할 |\n|---|---|\n| 내부노드 | 비교 속성 |\n| 간선(edge) | 속성 값 |\n| 단말노드 | 부류(class), 대표 값 |\n\n이런 결정 트리를 학습하는 알고리즘의 종류에 대해 알아보도록 하겠습니다.\n\n### 정보 이득(IG)\n\n데이터로부터 결정 트리를 생성하는 알고리즘으로, 모든 데이터를 포함한 하나의 노드로 구성된 트리에서 시작하여, 반복적인 노드 분할 과정을 거치며 서브 트리를 만들어갑니다.\n\n트리는 간단하게 표현될수록(depth가 낮을수록) 좋은데, 이를 달성하기 위해서는 **분류력이 높은$^*$** 속성을 상위 노드에 배치하는 것이 좋습니다.\n($^*$분류력이 높다: 분류된 결과들이 비슷한 부류일수록 분류력이 높음)\n\n이 때, 분할 속성을 결정할 때, 분류력이 높음을 수치화할 수 있을까요?\n이 척도로 엔트로피 개념이 사용됩니다.\n\n엔트로피는 비동질(불순도) 정도의 척도로, 클수록 비동질적이라는 뜻입니다.\n즉, 엔트로피가 작을수록 동질성이 크다는 의미인데, 정보량 측정 목적의 척도로 사용됩니다.\n\n정보량(I) 및 정보 이득(IG)은 아래와 같이 수식화 할 수 있으며, 정보 이득이 클수록 엔트로피의 차이가 크다는 뜻이고, 이는 우수한 분할 속성으로 분할되었다는 의미입니다.\n\n$$\nI = -\\sum_{c}p(c)log_2p(c) \\\\\nI_{res} = -\\sum_{v}p(v) \\sum_{c}p(c|v)log_2p(c|v) \\\\\nIG = I - I_{res}(A)\n$$\n\n여기서 **p는 부류별 확률**이고, 위 수식을 해석하면 다음과 같습니다.\n부모 엔트로피가 $I$이고, 자식 트리의 엔트로피 가중 평균이 $I_{res}$일 때, 그 차이가 커야 부모 노드(속성)을 잘 선택해서 분류했다는 뜻입니다.\n\n예를 들어 이해해봅시다.\n\n![231208-220043](/posts/final_01/231208-220043.png)\n\n이런 데이터를 분류한다고 가정해봅시다.\n이 때의 I는 아래와 같이 계산할 수 있습니다.\n\n$$\nI = - \\frac{5}{14}log_2\\frac{5}{14} - \\frac{9}{14}log_2\\frac{9}{14} = 0.940\n$$\n\n- Case 1: Pattern으로 분류\n\n    ![231208-220649](/posts/final_01/231208-220649.png)\n\n    Pattern이 수평, 대각선, 수직인지에 따라 분류할 경우 $I_{res}$를 계산해봅시다.\n\n    $$\n    I_{horizontal} = - \\frac{2}{5}log_2\\frac{2}{5} - \\frac{3}{5}log_2\\frac{3}{5} = 0.971 \\\\\n    {}\\\\\n    I_{digonal} = - \\frac{0}{4}log_2\\frac{0}{4} - \\frac{4}{4}log_2\\frac{4}{4} = 0 \\\\\n    {}\\\\\n    I_{vertical} = - \\frac{3}{5}log_2\\frac{3}{5} - \\frac{2}{5}log_2\\frac{2}{5} = 0.971 \\\\\n    {}\\\\\n    I_{res}(Pattern) = \\frac{5}{14} \\cdot 0.971 + \\frac{4}{14} \\cdot 0 + \\frac{5}{14} \\cdot 0.971 = 0.694\n    $$\n\n    즉, 분류 기준이 Pattern인 경우 IG = 0.246이 나옵니다.\n\n- Case 2: Outline으로 분류\n\n    ![231208-221128](/posts/final_01/231208-221128.png)\n\n    Outline이 점선, 실선인지에 따라 분류할 경우 $I_{res}$를 계산해봅시다.\n\n    $$\n    I_{dashed} = - \\frac{4}{7}log_2\\frac{4}{7} - \\frac{3}{7}log_2\\frac{3}{7} = 0.985 \\\\\n    {}\\\\\n    I_{solid} = - \\frac{1}{7}log_2\\frac{1}{7} - \\frac{6}{7}log_2\\frac{6}{7} = 0.592 \\\\\n    {}\\\\\n    I_{res}(Outline) = \\frac{7}{14} \\cdot 0.985 + \\frac{7}{14} \\cdot 0.592 = 0.789\n    $$\n\n    즉, 분류 기준이 Outline인 경우 IG = 0.151이 나옵니다.\n\n- Case 3: Dot으로 분류\n\n    ![231208-221413](/posts/final_01/231208-221413.png)\n\n    Dot이 있는지, 없는지에 따라 분류할 경우 $I_{res}$를 계산해봅시다.\n\n    $$\n    I_{no} = - \\frac{2}{8}log_2\\frac{2}{8} - \\frac{6}{8}log_2\\frac{6}{8} = 0.811 \\\\\n    {}\\\\\n    I_{yes} = - \\frac{3}{6}log_2\\frac{3}{6} - \\frac{3}{6}log_2\\frac{3}{6} = 1 \\\\\n    {}\\\\\n    I_{res}(Dot) = \\frac{8}{14} \\cdot 0.811 + \\frac{6}{14} \\cdot 1 = 0.892\n    $$\n\n    즉, 분류 기준이 Dot인 경우 IG = 0.048이 나옵니다.\n\n즉, 이 경우에는 첫번째 분류 기준으로 Pattern을 선택하는 것이 합리적입니다.\n다음 분류기준을 선택할 때도 이와 동일한 방법으로 진행하면 되지만, 다음 분류기준을 Pattern으로 선택하는 것은 의미가 없기에 선택하지 않도록 주의합니다.\n\n![231208-221914](/posts/final_01/231208-221914.png)\n\n하지만, 정보 이득(IG) 척도의 단점 역시 존재합니다.\n분류기준을 선택함에 있어 **속성값이 많은 것을 선호**한다는 것입니다.\n\n예로 들어 학번같은 경우, 학번은 유니크하기 때문에 분류시 학번별로 노드가 만들어지고, 그에 따라 엔트로피가 아주 낮게 측정되어 학번이 분류기준으로 선택될 것입니다.\n하지만, 학번으로 분류하는 것은 의미가 없죠.\n\n뿐만 아니라, **학습 데이터 셋에 없던 속성값의 경우 분류가 불가능**하다는 단점 또한 존재합니다.\n\n### 정보 이득 비(IG Ratio)\n\n속성값이 많은 것을 선호하는 문제를 해결하기 위한 개선된 알고리즘으로, 속성값이 많은 속성에 대한 불이익을 주는 방향으로 동작합니다.\n\n$$\nGainRatio(A) = \\frac{IG(A)}{I(A)} = \\frac{I - I_{res}(A)}{I(A)} \\\\\n{}\\\\\nI(A) = - \\sum_{v}p(v)log_2p(v)\n$$\n\n여기서 I(A)는 고유 엔트로피로, 속성 A의 속성값을 부류로 간주하여 계산한 엔트로피를 의미합니다.\n즉, 속성값이 많아질수록 엔트로피가 커지게 되므로, 학번을 분류기준으로 삼았을 때의 오류를 해결할 수 있습니다.\n\n앞의 `Case - Pattern`을 예로 들어봅시다.\n\n\n![231208-220649](/posts/final_01/231208-220649.png)\n\n$$\nI_{res}(Pattern) = \\frac{5}{14} \\cdot 0.971 + \\frac{4}{14} \\cdot 0 + \\frac{5}{14} \\cdot 0.971 = 0.694 \\\\\n{}\\\\\nI(Pattern) = - \\frac{5}{14}log_2\\frac{5}{14} - \\frac{4}{14}log_2\\frac{4}{14} - \\frac{5}{14}log_2\\frac{5}{14} = 1.58 \\\\\n{}\\\\\nGainRatio(Pattern) = \\frac{IG(Pattern)}{I(Pattern)} = \\frac{0.940 - 0.694}{1.58} = 0.156\n$$\n\n같은 방식으로 다른 분류기준에 대해 계산하면 다음과 같은 결과가 나옵니다.\n\n| 분류속성 | 속성의 개수 | IG | IG Ratio |\n|---|---|---|---|\n| Pattern | 3 | 0.247 | 0.156 |\n| Outline | 2 | 0.152 | 0.152 |\n| Dot | 2 | 0.048 | 0.049 |\n\n### 지니 이득(Gini Gain)\n\n다른 분류 알고리즘으로 지니 지수를 사용하는 방법도 있습니다.\n\n$$\nGini = \\sum_{i \\neq j}p(i)p(j)\n$$\n\n지니 지수는 위와 같이 수식화하며, 순도가 높을수록 낮은값이 나오게 됩니다.\n이를 이용한 지니 지수 이득은 아래와 같습니다.\n\n$$\nGini(A) = \\sum_{v}p(v) \\sum_{i \\neq j}p(i|v)p(j|v) \\\\\n{}\\\\\nGiniGain(A) = Gini - Gini(A)\n$$\n\n부모의 지니 지수에서 분류된 자식 트리의 지니 지수의 가중평균을 뺌으로서 구할 수 있습니다.\n마찬가지로 앞의 `Case - Pattern`을 예로 들어봅시다.\n\n![231208-220649](/posts/final_01/231208-220649.png)\n\n$$\nGini = \\frac{5}{14} \\times \\frac{9}{14} = 0.230 \\\\\n{}\\\\\nGini(Pattern) = \\frac{5}{14} \\times (\\frac{2}{5} \\times \\frac{3}{5}) + \\frac{4}{14} \\times (\\frac{0}{4} \\times \\frac{4}{4}) + \\frac{5}{14} \\times (\\frac{3}{5} \\times \\frac{2}{5}) = 0.171 \\\\\n{}\\\\\nGiniGain(Pattern) = 0.230 - 0.171 = 0.058\n$$\n\n같은 방식으로 다른 분류기준에 대해 계산하면 다음과 같은 결과가 나옵니다.\n\n| 분류속성 | IG | IG Ratio | Gini Gain\n|---|---|---|---|\n| Pattern | 0.247 | 0.156 | 0.058 |\n| Outline | 0.152 | 0.152 | 0.046 |\n| Dot | 0.048 | 0.049 | 0.015 |\n\n### 회귀(Regression)\n\n단말노드가 부류(class)가 아닌 수치(대표)값에 해당하는 경우 사용할 수 있는 분류법입니다.\n\n표준편차 축소 SDR를 최대로 하는 속성을 선택하는게 졸으며, SDR은 아래와 같은 수식으로 표현 가능합니다.\n\n$$\nSDR(A) = SD - SD(A) \\\\\n{}\\\\\nSD = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (x_i-m)^2} \\\\\n{}\\\\\nSD(A) = \\sum_{v}p(v) \\sqrt{\\frac{1}{N_v} \\sum_{i=1}^{N_v} (x_i-m_v)^2}\n$$\n\n---\n\n## 단순 베이즈 분류기\n\n결정 트리의 학습 알고리즘과 다르게 부류(class) 결정 지식을 조건부 확률로서 결정하는 분류기 입니다.\n\n\u003ctip\u003e\n  조건부 확률\n  $$\n  P(c|x_1, x_2, ..., x_n)\n  $$\n  \u003cbr /\u003e\n  베이즈 정리\n  $$\n  P(c|x_1, x_2, ..., x_n) = \\frac{P(x_1, x_2, ..., x_n|c)P(c)}{P(x_1, x_2, ..., x_n)} \\\\\n  {}\\\\\n  사후확률 = \\frac{가능도 \\times 사전확률}{증거}\n  $$\n\u003c/tip\u003e\n\n단순 베이즈 분류기는 베이즈 정리를 이용해서 분류를 하는데, 단순의 정의는 다음과 같습니다.\n\n\u003e 가능도가 조건부 독립이라고 가정\n\n즉, 베이즈 정리를 다음과 같이 정의합니다.\n\n$$\nP(c|x_1, x_2, ..., x_n) = \\frac{P(x_1|c)P(x_2|c)...p(x_n|c)P(c)}{P(x_1, x_2, ..., x_n)}\n$$\n\n예를 들어 이해해봅시다.\n\n![231208-220043](/posts/final_01/231208-220043.png)\n\n여기서 수직이며, 점선이고, 점이 없을 때 삼각형일 확률을 구해봅시다.\n\n$$\nP(삼각형|수직,점선,무) \\\\\n{}\\\\\n= \\frac{P(수직|삼각형)P(점선|삼각형)P(무|삼각형)P(삼각형)}{P(수직,점선,무)} \\\\\n{}\\\\\n= \\frac{3/5 \\cdot 4/5 \\cdot 2/5 \\cdot 5/14}{2/14} = 0.48\n$$","slug":"univ_ai/final_01","readingMinutes":11,"wordCount":977},{"title":"기계학습 - 비지도 \u0026 반지도학습","description":"비지도 \u0026 반지도학습에서 사용되는 개념에 대해 알아봅니다.","icon":"","image":"","tags":["Unsupervised learning","Clustering","Semi-supervised learning"],"draft":false,"date":"2023-10-22 / 22:58","content":"\n## 비지도학습\n\n지도학습은 학습 데이터에 입력-출력이 명시되어 있었는데, 비지도학습은 학습 데이터에 어떠한 레이블도 붙지 않은 데이터를 이용한 학습 방법을 의미한다.\n\n비지도학습을 통해 데이터에 대한 잠재적인 구조나 계층 구조를 찾을 수 있고, 문서들을 주제에 따라 구조화 하거나, 로그를 분석한 사용 패턴을 알아내는데 적용할 수 있다.\n\n---\n\n## 군집화\n\n유사성에 따라 데이터를 분할하는 것으로, 데이터가 하나의 군집에만 소속되는 일반 군집화(Hard clustering)와 퍼지 군집화(Fuzzy clustering)으로 나뉜다.\n\n군집화는 보통 아래와 같은 용도로 사용된다.\n\n- 데이터에 내제된/일반적 구조 추정/통찰\n- 가설 설정\n- 이상 감지\n- 데이터 압축\n- 데이터 전처리 (부류(class)를 부여하는 방식)\n\n성능은 군집 내의 분산은 작을수록, 군집간의 거리는 멀수록 좋다고 평가한다.\n\n### 밀도 추정\n\n![231022-230608](/posts/mid_08/231022-230608.png)\n\n부류(class)별로 데이터를 만들어 냈을 것으로 추정되는 확률 분포를 찾는 과정으로, 각 부류 별로 주어진 데이터를 발생시키는 확률을 계산하여 가장 확률이 높은 부류로 데이터를 분류한다.\n\n분포가 수학적인 형태를 갖고있을 것을 가정하여 데이터의 분포를 가장 잘 수학적으로 표현하려고 하는 추정 방식을 `모수적 밀도 추정` 이라고 하며, 전형적으로 **Gaussian 함수의 혼합**으로 표현한다.\n\n또는, 분포에 대한 수학적 함수를 가정하지 않고, 주어진 데이터를 사용하여 밀도함수의 형태로 표현하는 방식을 `비모수적 밀도 추정` 이라고 하며, 전형적으로 **히스토그램**과 같은 방식으로 표현한다.\n\n### 차원 축소\n\n고차원의 데이터를 정보의 손실을 최소화 하면서 저차원으로 변환하는 것으로, 시각화를 직관적으로 하기 위해, 그리고 `차원의 저주 문제`를 완화하기 위해 사용한다.\n\n\u003ctip\u003e\n  `차원의 저주 문제`\n  \u003cbr /\u003e\n  ![231022-231121](/posts/mid_08/231022-231121.png)\n  차원이 커질수록 거리분포가 일정해지는 경향\n\u003c/tip\u003e\n\n![231022-231254](/posts/mid_08/231022-231254.png)\n\n이를 위해 주성분을 분석하여 분산이 큰 축을 기준으로 데이터를 projection하는 방식을 사용해서 저차원으로 변환한다.\n\n### 이상치 탐지\n\n다른 데이터와 크게 달라서 관심 대상으로 봐야하는 데이터를 탐지하기 위해 사용한다.\n이런 관심대상의 데이터는 `노이즈`일 확률이 높으나, `신규성 탐지`의 경우도 항상 염두해야 한다.\n\n이상치는 아래와 같은 방식으로 탐지할 수 있다.\n\n- 점 이상치\n  다른 데이터와 비교하여 차이가 큰 데이터\n\n- 상황적 이상치\n  상황에 맞지 않는 데이터\n\n- 집단적 이상치\n  여러 데이터를 모아서 보면 비정상으로 보이는 데이터\n\n이러한 이상치 탐지는 **부정사용감지 시스템**이나 **침임감지 시스템** 등에 사용할 수 있다.\n\n---\n\n## 반지도학습\n\n비지도학습과 마찬가지로 미분류 데이터를 이용하는데, 이를 지도학습에 사용하는 방법이다.\n\n![231022-231828](/posts/mid_08/231022-231828.png)\n\n이런 식으로 같은 군집에 속하는 것은 가능한 동일한 부류에 소속하도록 학습하는 방식이다.\n미분류 데이터는 획득 비용이 낮기 때문에 이러한 지도학습 방식도 고려하면 좋다.\n\n단, 반지도학습을 위해서는 데이터가 아래와 같은 경향을 보인다는 가정하에 이루어져야 한다.\n\n- 평활성 가정\n  가까이 있는 점들은 서로 같은 부류에 속할 가능성이 높음\n\n- 군집 가정\n  같은 군집에 속하는 데이터는 서로 같은 부류에 속할 가능성이 높음\n\n- 매니폴드(Manifold) 가정\n  원래 차원보다 낮은 차원의 매니폴드에 데이터가 분포할 가능성이 높음","slug":"univ_ai/mid_08","readingMinutes":6,"wordCount":382},{"title":"기계학습 - 지도학습","description":"지도학습에서 사용되는 개념에 대해 알아봅니다.","icon":"","image":"","tags":["Supervised learning","Classification","Regression"],"draft":false,"date":"2023-10-22 / 22:02","content":"\n## 기계학습\n\n사례들(examples)을 일반화하여 패턴 또는 모델을 추출하는 과정으로 학습 데이터를 잘 설명할 수 있는 패턴을 기계 스스로 학습하는 것을 유도하는 것이다.\n\n![231022-220530](/posts/mid_07/231022-220530.png)\n\n단, 오컴의 면도날(Occam's razor) 원리에 따라 가능하면 학습 결과가 간단한 형태로 표현되면 좋다.\n\n기계학습의 종류에는 지도학습, 비지도학습, 반지도학습, 강화학습과 같은 방법이 있는데, 이번에는 지도학습에 대해서만 알아보자.\n\n### 지도학습\n\n주어진 학습 데이터 - **(입력, 출력)** 과 같은 데이터를 이용해서 학습하는 과정.\n학습이 완료된 모델은 새로운 **(입력)** 이 있을 때 **(출력)** 을 유추할 수 있어야 한다.\n\n출력이 불 연속적인 값이어야 한다면 데이터를 `분류`하는 방향으로 학습을 해야하고,\n출력이 연속적인 값이어야 한다면 `회귀`하는 방향으로 학습을 해야한다.\n\n---\n\n## 분류 (Classification)\n\n이상적인 분류기는 학습에 사용되지 않은 데이터에 대해서 분류를 잘 해야한다.\n즉, 일반화의 능력이 좋은것이 이상적인 분류기이다.\n\n\u003ctip\u003e\n  데이터의 종류\n  1. 학습 데이터\n    분류기를 학습하는데 사용하는 데이터 집합.\n  2. 테스트 데이터\n    학습된 모델의 성능을 평가하는데 사용하는 데이터 집합.\n    학습에 사용되지 않은 데이터여야 함.\n  3. 검증 데이터\n    학습 과정에서 학습을 중단할 시점을 결정하기 위해 사용하는 데이터 집합.\n\u003c/tip\u003e\n\n![231022-221446](/posts/mid_07/231022-221446.png)\n\n학습 데이터를 충분히 학습하지 않은 상태를 `부적합` 이라고 한다.\n\n반대로학습 데이터에 대해 지나치게 잘 학습된 상태를 `과적합` 이라고 하는데, 학습되지 않은 데이터에 대해 좋지 못할 성능을 보일 가능성이 크다.\n과적합을 회피하기 위해서 검증 데이터를 사용하게 된다.\n\n![231022-221636](/posts/mid_07/231022-221636.png)\n\n검증 데이터에 대한 오류가 증가하기 시작하면 학습 데이터에 대해 과적합이 일어나는 시점이기 때문에 이 때 학습을 중지하는 것이 좋다.\n\n### 불균형 데이터 문제\n\n특정 부류에 속하는 학습 데이터의 개수가 **다른 부류에 비해 지나치게 많은 경우** 정확도에 의한 성능 평가가 무의미해진다.\n이게 무슨 의미냐면, A 부류의 데이터가 전체 데이터의 99%를 차지한다면, 분류기의 출력을 항상 A로 설정하는 경우 해당 학습 데이터에 대해 99%의 정확도를 보일 것이다.\n하지만, 테스트 데이터에선 A/B가 각각 50% 비율로 들어있다면, 분류기의 정확도는 50%로 감소할 것이다.\n\n![231022-222326](/posts/mid_07/231022-222326.png)\n\n이런 경우 SMOTE 알고리즘을 이용해 어느정도 해결할 수 있다.\n간단하게 설명하면 빈도가 낮은 학습 데이터의 `k-근접 이웃`을 이용해 새로운 데이터를 생성하여 빈도가 낮은 부류의 데이터 개수를 늘리는 알고리즘이다.\n\n### 이진 분류기 성능 평가\n\n이진 분류기는 두 개의 부류만을 갖는 데이터에 대한 분류기로 A/B 둘 중 하나로 분류하는 분류기이다.\n이 분류기는 아래와 같은 예측-결과 표를 생성하는데,\n\n![231022-222646](/posts/mid_07/231022-222646.png)\n\n이것을 이용한 여러가지 지표로 성능을 평가한다.\n\n- 민감도/재현율/진양성율\n  실제 양성일 때, 양성이라고 예측하는 확률이다.\n  \u003e 민감도 = $\\frac{TP}{TP + FN}$\n  \u003e\n  \u003e e.g. 불이났을 때, 불이 났다고 민감하게 알려주는 화재경보기\n\n- 특이도/진음성률\n  실제 음성일 때, 음성이라고 예측하는 확률이다.\n  \u003e 특이도 = $\\frac{TN}{TN + FP}$\n  \u003e\n  \u003e e.g. 불이 안났을 때, 울리지 않는 화재경보기\n\n- 정밀도\n  양성으로 예측을 했는데, 실제로 양성일 확률.\n  \u003e 정밀도 = $\\frac{TP}{TP + FP}$\n  \u003e\n  \u003e e.g. 화재경보기가 경보를 울렸는데, 실제로 불이 난 상황이었음\n\n- 음성 예측도\n  음성으로 예측을 했는데, 실제로 음성일 확률.\n  \u003e 음성 예측도 = $\\frac{TN}{TN + FN}$\n  \u003e\n  \u003e e.g. 화재경보기가 안울렸는데, 실제로 불도나지 않았음\n\n- 위양성율\n  1에서 특이도를 뺀 값.\n  \u003e 위양성율 = $\\frac{FP}{TN + FP}$ = 1 - 특이도\n\n- 위발견율\n  1에서 정밀도를 뺀 값.\n  \u003e 위발견율 = $\\frac{FP}{TP + FP}$ = 1 - 정밀도\n\n- 정확도\n  예측한대로 결과가 나올 확률.\n  \u003e 정확도 = $\\frac{TP + TN}{TP + FP + TN + FN}$\n\n- F1 측도\n  \u003e F1 = 2$\\frac{정밀도 \\times 재현율}{정밀도 + 재현율}$\n\n### ROC 곡선\n\n위양성률, 민감도 그래프로 ROC 곡선의 아래 면적, AUC(Area Under the Curve)가 클수록 바람직하게 분류한다는 뜻이다.\n\n![231022-224153](/posts/mid_07/231022-224153.png)\n\n---\n\n## 회귀 (Regression)\n\n학습 데이터에 부합되는 출력값이 실수인 함수를 찾는 문제로, 앞에서 언급했 듯, 출력이 연속적이어야 하는 경우에 사용하는 방법이다.\n\n![231022-224546](/posts/mid_07/231022-224546.png)\n\n파란 점과 같은 학습 데이터가 주어졌을 떄, 해당 데이터를 가장 잘 설명하는 모델 **$f$** 를 찾기 위해서는 $f$의 오차를 계산하는 함수 **$f*$** 이 최소가 되도록 인자를 조정해야 한다.\n\n$$\nf*(x) = argmin_f \\sum_{i=1}^{n} (y_i - f(x_i))^2\n$$\n\n### 회귀 성능 평가\n\n학습 방향성과 같다.\n테스트 데이터에 대한 오차값의 평균이 작을수록 좋다.\n\n![231022-225021](/posts/mid_07/231022-225021.png)\n\n하지만 처음에 언급했 듯 과적합되는 현상은 피해야 한다.\n\n이를 위해 모델의 복잡도를 일종의 **패널티**로써 성능 평가(목적함수)에 반영하여, 모델의 복잡도를 최소화 하는 방향으로 학습을 유도해야 한다.\n\n### 로지스틱 회귀 (Logistic regression)\n\n모델의 출력이 [0, 1] 사이의 값을 갖도록 조정해야 하는 경우 sigmoid 함수와 같은 로지스틱 함수를 이용해서 학습 데이터의 출력을 근사하는 방식을 사용할 수도 있다.\n\n![231022-225434](/posts/mid_07/231022-225434.png)\n\n단, 이 때의 목적 함수는 `교차 엔트로피`(오차가 0~1 사이로 조정됨)가 적용된 함수를 사용해야 한다.\n\n로지스틱 회귀는 경사 하강법을 사용하는 학습에서 자주 사용된다.","slug":"univ_ai/mid_07","readingMinutes":9,"wordCount":660},{"title":"규칙 기반 시스템","description":"지식을 규칙의 형태로 표현하는 방법에 대해 알아봅니다.","icon":"","image":"","tags":["전향 추론","후향 추론","규칙 기반 시스템"],"draft":false,"date":"2023-10-22 / 19:59","content":"\n## 추론\n\n구축된 지식과 주어진 데이터, 정보를 이용해 새로운 사실을 생성하는 것으로 전향(순방향) 추론과 후향(역방향) 추론으로 나뉜다.\n\n### 전향 추론\n\n규칙의 조건부와 만족하는 사실이 있을 때 규칙의 결론부를 실행하거나 처리하는 방식으로 아래와 같이 순방향으로 추론하는 방식이다.\n\n![231022-200403](/posts/mid_06/231022-200403.png)\n\n### 후향 추론\n\n어떤 사실을 검증하거나 확인하고 싶은 경우에 관심 대상의 사실을 결론부에 갖고 있는 규칙을 찾아서 조건부가 만족하는지를 확힌하는 방식으로 아래와 같이 역방향으로 추론하는 방식이다.\n\n![231022-200616](/posts/mid_06/231022-200616.png)\n\n---\n\n## 규칙 기반 시스템\n\n지식을 규칙과 사실로 기술하며 아래와 같은 구조로 관리된다.\n\n![231022-200851](/posts/mid_06/231022-200851.png)\n\n**문제 해결을 위한 지식**인 `규칙`은 규칙 베이스에서 관리되며, 생성 메모리 라고도 불린다.\n\n**문제에 대해 알려진 데이터나 정보**인 `사실`은 작업 메모리에서 관리된다.\n참고로, 추론 과정의 중간 결과나 사용자로부터 받은 문제에 대한 정보 역시 여기서 관리된다.\n\n### 추론 엔진\n\n실행할 수 있는 규칙을 찾아 해당 규칙을 실행하는데 아래의 3단계의 과정을 반복한다.\n\n1. 패턴 매칭\n  작업 메모리의 사실과 규칙 메모리에 있는 규칙의 조건부를 대조하여 일치하는 규칙을 찾아냄.\n\n2. 경합 해소\n  찾아낸 규칙 중 경합되는 규칙(경합 집합)에 대해 하나의 규칙을 선택함.\n  경합 해소 전략에는 다음과 같은 전략이 있음.\n\n    \u003e 1. 규칙 우선\n    \u003e 미리 규칙에 우선순위를 부여하고, 경합시 우선순위가 높은 규칙을 우선 선택\n    \u003e 우선순위 태그 기준\n    \u003e ![231022-201805](/posts/mid_06/231022-201805.png)\n    \u003e\n    \u003e 2. 최신 우선\n    \u003e 가장 최근에 입력된 데이터와 매칭된 규칙을 우선 선택\n    \u003e 시간 태그 기준\n    \u003e ![231022-201845](/posts/mid_06/231022-201845.png)\n    \u003e\n    \u003e 3. 최초 우선\n    \u003e 경합 집합에서 가장 먼저 매칭된 규칙을 우선 선택\n    \u003e\n    \u003e 4. 상세 우선\n    \u003e 조건부가 가장 상세하거나 복잡한 규칙을 우선 선택\n    \u003e 태그말고 조건문의 길이 기준\n    \u003e ![231022-201826](/posts/mid_06/231022-201826.png)\n    \n\n3. 규칙 실행","slug":"univ_ai/mid_06","readingMinutes":4,"wordCount":241},{"title":"불확실한 지식 표현","description":"불확실한 지식을 표현하는 방법에 대해 알아봅니다.","icon":"","image":"","tags":["Certainty factor","Probability","Fuzzy"],"draft":false,"date":"2023-10-22 / 19:10","content":"\n인과성이 약하거나, 연관성이 애매하거나, '얼마나?'에 해당하는 정도가 모호한 문장을 정량화 하는 방법에 대해 알아봅니다.\n\n## 확신도 (Certainty factor)\n\n규칙과 사실의 신뢰정도를 [-1, 1] 구간의 값으로 표현합니다.\n\n| 확신도 | 대응되는 단어 |\n|---|---|\n| −1.0 | 절대 아니다 (definitely not)|\n| −0.8 | 거의 확실히 아니다 (almost certainly not) |\n| −0.6 | 아마 아니 것이다 (probably not) |\n| −0.4 | 어쩌면 아닐 것이다 (maybe not) |\n| −0.2 ~ 0.2 | 모르겠다 (unknown) |\n| 0.4 | 어쩌면 그럴 것이다 (maybe) |\n| 0.6 | 아마 그럴 것이다 (probably) |\n| 0.8 | 거의 확실하다 (almost certainly) |\n| 1.0 | 확실하다 (definitely)|\n\n### 추론결과의 확신도\n\n추론에 대한 확신도는 각 명제에 대한 확신도를 계산하여 도출해야 합니다.\n\n- IF A THEN B _($\\{A \\rightarrow B, \\; A\\} \\vdash B$)_\n  기본적으로 정형식들의 확신도를 곱하는 방식으로 구합니다.\n  \u003e **$cf(B) = cf(A) \\times cf(A \\rightarrow B)$**\n\n- IF A and B THEN C _($\\{A \\wedge B \\rightarrow C, \\; A, \\; B\\} \\vdash C$)_\n  **and**의 경우 조건부에 해당하는 정형식의 확신도 중 작은 값을 고릅니다.\n  \u003e **$cf(C) = min\\{cf(A), cf(B)\\} \\times cf(A \\wedge B \\rightarrow C)$**\n\n- IF A or B THEN C _($\\{A \\vee B \\rightarrow C, \\; A, \\; B\\} \\vdash C$)_\n  **or**의 경우 조건부에 해당하는 정형식의 확신도 중 큰 값을 고릅니다.\n  \u003e **$cf(C) = max\\{cf(A), cf(B)\\} \\times cf(A \\vee B \\rightarrow C)$**\n\n아래는 예시입니다.\n\n![231022-192422](/posts/mid_05/231022-192422.png)\n\n만약, 여러 사실에 의해 동일한 사실을 추론하는 경우 추론 결과는 같지만, 확신도는 다르게 계산될 수 있습니다.\n이런 경우, 확신도를 하나로 통합하는게 좋습니다.\n\n![231022-192640](/posts/mid_05/231022-192640.png)\n\n---\n\n## 확률 (Probability)\n\n어떤 사건이 일어날 가능성을 표현할 때 사용합니다.\n\n### 결합 확률\n\n사건 A, B가 동시에 일어날 확률을 가리키며, 아래와 같이 수식화 할 수 있습니다.\n\n\u003e A: 첫 번째 주사위가 짝수\n\u003e B: 두 번째 주사위가 홀수\n\u003e\n\u003e $P(A,B) = P(A \\cap B) = P(AB)$\n\u003e $= 1/2 \\times 1/2 = 0.25$\n\n### 조건부 확률\n\n사건 B가 일어났을 때, 사건 A가 일어날 확률을 가리키며, 아래와 같이 수식화 할 수 있습니다.\n\n\u003e A: 두 주사위의 합이 8\n\u003e B: 첫 번째 주사위가 3\n\u003e\n\u003e $P(A|B) = \\frac{P(A,B)}{P(B)}$\n\u003e $= \\frac{1/36}{1/6} = 1/6$\n\n`베이즈 정리`에 의해 조건부 확률의 조건부를 변형할 수 있습니다.\n\n\u003e $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n\n---\n\n## 퍼지 이론 (Fuzzy theory)\n\n기존 집합론과 다르게 퍼지 이론은 0/1의 이분법적으로 분류하지 않고, 0~1로 모호하게(어느정도 포함되게) 구분함.\n즉, 어느 정도(degree)의 문제는 퍼지 집합을 도입하여 해결.\n\n### 퍼지 집합\n\n원소가 모임(collection)에 어느 정도 속한다는 것을 표현한 것으로, 해당 집합은 부분적으로 참이 됨.\n소속정도는 [0, 1] 범위의 실수값으로 표현함.\n\n작다, 평균이다, 크다의 표현을 아래와 같이 다르게 할 수 있음.\n\n![231022-194330](/posts/mid_05/231022-194330.png)\n\n### 퍼지 규칙\n\n소속함수로 표현된 언어항을 표함하는 규칙.\n\n\u003e IF service = 나쁘다 OR food = 별로이다 THEN tip = 적다\n\u003e IF service = 보통이다 THEN tip = 보통이다\n\u003e IF service = 훌륭하다 OR food = 맛있다 THEN tip = 많다\n\n\u003ctip\u003e\n  `언어항`\n  '나쁘다', '맛있다', '많다'와 같은 자연어에 해당하는 항으로 소속함수로 표현될 수 있다. \n  ![231022-194851](/posts/mid_05/231022-194851.png)\n\u003c/tip\u003e\n\n### 퍼지 추론\n\n소속함수로 표현돤 언어항을 사용하는 퍼지 규칙들의 모음으로 수치적인 추론이 가능해진다.\n\n![231022-195645](/posts/mid_05/231022-195645.png)\n\n추론된 영역의 무게중심을 결과로 사용하면 `비퍼지화`가 가능하다.","slug":"univ_ai/mid_05","readingMinutes":5,"wordCount":496},{"title":"명제 논리 \u0026 술어 논리","description":"지식을 표현하는 방법 - 논리에 대해 알아봅니다.","icon":"","image":"","tags":["Proposition","Predicate"],"draft":false,"date":"2023-10-22 / 15:48","content":"\n말로 표현된 문장을 타당한 추론을 위해 기호를 사용하여 표현하고, 기호의 조작을 통해 참과 거짓을 판정하는 분야이다.\n\n## 명제 논리\n\n### 명제 (Proposition)\n\n`명제`란, 참과 거짓을 분평하게 판정할 수 있는 문장으로 P, Q와 같은 기호로 표현된다.\n\n중요한 점은, 명제 그 자체는 참, 거짓을 결정할 수 없고, 반드시 기호의 진리값을 설정해 줘야 한다는 점이다.\n이게 무슨 말이냐면, 아래의 문장을 예로 들어 설명해보겠다.\n\n\u003e 오징어 다리는 10개 이다.\n\n이 명제는 우리나라에서는 참이다.\n하지만 북한에서는 오징어 라는 명사는 우리나라의 낙지를 가리키는 말 이기 때문에 북한에서는 거짓인 명제이다.\n\n즉, 문장 자체의 내용에 대해서는 관심을 갖지 말고, 문장의 설정된 `진리값에만 관심`을 가져야 한다.\n\n_**용어 설명**_\n| 용어 | 의미 |\n|---|---|\n| 기본 명재 | 하나의 진술로만 이루어진 최소 단위의 명제 |\n| 복합 명제 | 기본 명제들이 결합되어 만들어진 명제 |\n\n### 논리식 (Logical expression)\n\n명제를 기호로 표현한 형식으로 명제기호, T/F, 논리 기호를 사용하여 구성되는데, 가장 기본이 되는 논리 기호는 다음과 같다.\n\n| 논리기호 | 이름 | 논리식 | 의미 |\n|---|---|---|---|\n| $\\neg$ | 부정 (negation) | $\\neg P$ | $P$가 아님 |\n| $\\vee$ | 논리합 (disjunction) | $P \\vee Q$ | $P$ 또는 $Q$ |\n| $\\wedge$ | 논리곱 (conjunction) | $P \\wedge Q$ | $P$ 그리고 $Q$ |\n| $\\rightarrow$ | 함의 (implication) | $P \\rightarrow Q$ | $P$ 이면 $Q$ |\n| $\\equiv$ | 동치 (equivalence) | $P \\equiv Q$ | $(P \\rightarrow Q) \\wedge (Q \\rightarrow P)$ |\n\n_**용어 설명**_\n| 용어 | 의미 |\n|---|---|\n| 리터럴 | 명제 기호 또는 명제 기호의 부정 |\n| 절 | 리터럴들이 논리합이나 논리곱으로만 연결 (논리합 절, 논리곱 절) |\n| 논리곱 정규형 (CNF) | 논리합 절들이 논리곱으로 연결되어 있는 논리식 |\n| 논리합 정규형 (DNF) | 논리곱 절들이 논리합으로 연결되어 있는 논리식 |\n| 정형식 (WFF) | 진리값(T/F)과 명제, 그들과 논리 기호를 사용하여 구성된 논리식을 의미함 |\n\n### 진리표 (Truth table)\n\n논리기호에 따라 T/F를 결합하는 방법을 나타낸 표\n\n| $P$ | $Q$ | $\\neg P$ | $P \\vee Q$ | $P \\wedge Q$ | $P \\rightarrow Q$ | $P \\equiv Q$ |\n|---|---|---|---|---|---|---|\n| F | F | **T** | F | F | **T** | **T** |\n| F | **T** | **T** | **T** | F | **T** | F |\n| **T** | F | F | **T** | F | F | F |\n| **T** | **T** | F | **T** | **T** | **T** | **T** |\n\n- 타당한 논리식 (Valid logical expression), 항진식\n  모든 가능한 해석에 대해 항상 참인 논리식\n  _e.g. $P \\vee \\neg P$_\n\n- 항위식\n  모든 가능한 해석에 대해 항상 거짓인 논리식\n  _e.g. $P \\wedge \\neg P$_\n\n- 츙족가능한 논리식\n  참으로 만들 수 있는 해석이 하나라도 있는 논리식\n\n- 충족불가능한 논리식\n  참으로 만들 수 있는 해석이 하나도 없는 논리식. 즉, 항위식.\n\n### 동치 관계 (Equivalence relation)\n\n어떠한 해석에 대해서도 같은 진리 값을 갖는 두 논리식\n\n- $\\neg(\\neg p) \\equiv p$\n- $p \\vee F \\equiv p$\n  $p \\wedge T \\equiv p$\n- $P \\vee \\neg P \\equiv T$\n  $P \\wedge \\neg P \\equiv F$\n- **$\\neg (p \\wedge q) \\equiv \\neg p \\vee \\neg q$**\n  **$\\neg (p \\vee q) \\equiv \\neg p \\wedge \\neg q$**\n- **$p \\rightarrow q \\equiv \\neg p \\vee q$**\n- $p \\vee (q \\vee r) \\equiv p \\vee q \\vee r$\n  $(p \\wedge q) \\wedge r \\equiv p \\wedge q \\wedge r$\n- **$p \\vee (q \\wedge r) \\equiv (p \\vee q) \\wedge (p \\vee r)$**\n  **$p \\wedge (q \\vee r) \\equiv (p \\wedge q) \\vee (p \\wedge r)$**\n\n### 논리적 귀결 (Logical entailment)\n\n정형식(Well-Formed Formula, WFF)의 집합 $\\Delta$가 다른 정형식 $\\omega$를 참으로 만든다면 두 관계를 아래와 같이 정의한다.\n\n\u003e $\\Delta \\models \\omega$\n\u003e e.g. $\\{P, \\; P \\rightarrow Q\\} \\models Q$\n\u003e\n\u003e $\\Delta$는 $\\omega$를 논리적으로 귀결한다.\n\u003e $\\omega$는 $\\Delta$를 논리적으로 따른다.\n\u003e $\\omega$는 $\\Delta$의 논리적 결론이다.\n\n### 추론 (Inference)\n\n논리적 귀결을 도출하는 과정을 추론이라고 한다.\n\n관측된 복수의 사실들을 일반화하여 일반적인 패턴(명제)를 도출하는 것을 `귀납적 추론` 이라고 하고,\n참인 명제(사실)들로부터 새로운 명제(사실)을 도출하는 것을 `연역적 추론` 이라고 한다.\n\n논리에서의 추론은 보통 **연역적 추론**을 가리키는데, 이걸 도출하는 테크닉에 대해 살펴보자.\n\n- 긍정 논법\n  $\\{p \\rightarrow q, \\; p\\} \\vdash q$\n  _(\\{새이다 \u0026rarr; 날 수 있다, 새이다\\} \u0026rarr; 날 수 있다)_\n\n- 부정 논법\n  $\\{p \\rightarrow q, \\; \\neg q\\} \\vdash \\neg p$\n  _(\\{새이다 \u0026rarr; 날 수 있다, 날 수 없다\\} \u0026rarr; 새가 아니다)_\n\n- 삼단 논법\n  $\\{p \\rightarrow q, \\; q \\rightarrow r\\} \\vdash p \\rightarrow r$\n  _(\\{새이다 \u0026rarr; 날개가 있다, 날개가 있다 \u0026rarr; 날 수 있다\\} \u0026rarr; 새이다 \u0026rarr; 날 수 있다)_\n\n- **논리 융합 (Resolution)**\n  긍정, 부정, 삼단 논법을 포함한 일반화된 추론 규칙으로 \n  두 개의 **논리합 절**이 같은 기호의 긍정-부정 리터럴을 서로 포함하고 있을 때, 해당 리터럴을 제외한 나머지 리터럴의 논리합 절을 만들어 내는 것.\n\n  | 논법 | 변환 | WFF (논리 융합식, Resolvent) |\n  |---|---|---|\n  | $p \\rightarrow q, \\; p$ | **$\\neg p$** $\\vee q$, **$p$** | $q$ |\n  | $p \\rightarrow q, \\; \\neg q$ | $\\neg p \\vee$ **$q$**, **$\\neg q$** | $\\neg p$ |\n  | $p \\rightarrow q, \\; q \\rightarrow r$ | $\\neg p \\vee$ **$q$**, **$\\neg q$** $\\vee r$ | $\\neg p \\vee r$ ($p \\rightarrow r$) |\n\n  즉, 논리 융합을 사용하면 모든 추론 규칙을 일반화 할 수 있다.\n\n- 정당성 (sound)\n  $\\Delta \\vdash \\omega \\; \\rightarrow \\; \\Delta \\models \\omega$ (아야 sound)\n\n- 완전성 (complete)\n  $\\Delta \\models \\omega \\; \\rightarrow \\; \\Delta \\vdash \\omega$ (야아 complete 하네)\n\n  \u003ctip\u003e\n    정당성과 완전성을 동시에 만족하는 추론 규칙은 논리적인 귀결과 동일시 할 수 있다.\n  \u003c/tip\u003e\n\n### 증명 (Proof)\n\n- 구성적 증명 (Constructive proof)\n  공리(참인 논리식)들에 추론 규칙을 적용하여 참을 만들어 보이는 증명.\n  정리하다가 결론이 참으로 끝나면 된다.\n\n- 논리융합 반박 (Resoultion refutation)\n  증명할 정리를 일단 부정하고, 논리융합 방법을 적용해 모순이 발생함으로 보이는 증명.\n  부정된 정리가 모순이니, 원상태의 정리는 참이 된다.\n\n  ![231022-171322](/posts/mid_04/231022-171322.png)\n\n---\n\n## 술어 논리\n\n명제의 내용을 다루기 위해 변수, 함수 등을 도입하고, 이들의 값에따라 T/F가 결정되도록 명제 논리를 확장한 논리.\n\n### 술어 (Predicate)\n\n대상의 속성이나 관계를 기술하는 기호로, 대상에게 T/F를 부여하는 명제의 기본 형식이다.\n\n| 문장 | 명제 논리 | 술어 논리 |\n|---|---|---|\n| 모든 사람은 죽는다 | P | $\\forall x(사람(x) \\rightarrow 죽는다(x))$ |\n| 소크라테스는 사람이다 | Q | $사람(소크라테스)$ |\n| 소크라테스는 죽는다 | R | $죽는다(소크라테스)$ |\n\n\u003ctip\u003e\n  `존재 한정사`\n  Existential quantifier로 존재함을 알려준다. (**$\\exist$**)\n  \u003cbr /\u003e\n  `전칭 한정사`\n  Universal quantifier로 모든 범위를 가리킨다. (**$\\forall$**)\n\u003c/tip\u003e\n\n### 함수 (function) / 항 (term)\n\n주어진 인자에 대해 T/F를 반환하는 것이 아닌, 일반작인 값을 반환하는 것을 `함수`라고 한다.\n즉, 인자를 지칭하기 위해 쓰인다.\n\n함수의 인자가 될 수 있는 것을 `항` 이라고 한다.\n**상수, 변수, 함수**만이 항이 될 수 있다.\n\n\u003ctip\u003e\n  명제 논리식의 정형식(WFF)과 마찬가지로, 술어 논리식의 정형식 역시 비슷한 정의를 갖는다.\n  항, 논리 기호, 한정사로만 이루어진 식을 정형식이라고 부른다.\n\u003c/tip\u003e\n\n### N차 술어 논리 (N-order predicate logic)\n\n**변수에만** 한정사를 사용할 수 있도록 한 술어 논리를 `일차 술어논리(FOL)` 라고 한다.\n엄밀히는, 술어기호의 인자로 사용될 수 있는 객체나 대상만을 변수화 할 수 있고, 이들 변수에만 전칭 한정사와 존재 한정사를 쓸 수 있도록 한 술어논리를 말한다.\n\n**변수, 함수, 술어기호**에 대해 한정사를 쓸 수 있도록 한 술어 논리를 `고차 술어논리(HOL)` 라고 한다.\n엄밀히는, 함수나 술어기호도 변수화 할 수 있고, 이들 변수에만 전칭 한정사와 존재 한정사를 쓸 수 있도록 한 술어논리를 말한다.\n\n인공지능 분야에서는 **연산량의 한계** 때문에 `일차 술어논리`를 주로 사용한다.\n\n### CNF 변환\n\n아래의 변환 과정을 거친면 된다.\n\n1. 한정사를 논리식의 맨 앞으로 끌어내는 변환\n  일반적으로 한정사를 맨 앞으로 끌어내도 의미는 변하지 않지만, 그래도 최다한 할 수 있는 변환을 한 뒤에 끌어내자.\n\n2. 전칭 한정사 제거\n  $\\forall$은 바로 제거해도 상관없다.\n\n3. 존재 한정사 제거\n  우선 아래와 같은 방식으로 전칭 한정사로 변환한 뒤 전칭 한정사를 제거하는 방법을 사용한다.\n  **$\\neg \\exist x P \\equiv \\forall x \\neg P$**\n\n    만일 함수에 변수가 2개 이상 사용된 경우 변환이 어려울 때는 상수를 집어넣거나 스콜렘 함수로 변환한다.\n    $\\forall x \\exist y [P(x) \\wedge$ **$Q(x, y)$**$] \\rightarrow \\forall x [P(x) \\wedge$ **$Q(x, s(x))$**$]$\n\n4. 단일화\n  논리 융합을 적용할 때, 대응되는 리터럴이 같아지도록 상수를 변수화 함.\n  ![231022-175353](/posts/mid_04/231022-175353.png)\n\n변환 과정을 거쳐 논리융합 반박을 통해 증명하는 예시를 살펴보자.\n아래의 예시는 (5)의 모순을 보임으로써 $\\neg$(5)가 참임을 보이는 논리융합 반박이다.\n\n![231022-175534](/posts/mid_04/231022-175534.png)","slug":"univ_ai/mid_04","readingMinutes":13,"wordCount":1309},{"title":"프레임 \u0026 의미망 \u0026 스크립트","description":"지식을 표현하는 방법 - 프레임, 의미망, 스크립트에 대해 알아봅니다.","icon":"","image":"","tags":["Frame"],"draft":false,"date":"2023-10-22 / 15:35","content":"\n## 프레임 (Frame)\n\n특정 객체 또는 개념에 대한 전형적인 지식을 슬롯(slot)의 집합으로 표현하는 것으로, 컴퓨터를 표현한 프레임은 다음과 같이 기술할 수 있다.\n\n![231022-153840](/posts/mid_03/231022-153840.png)\n\n### 슬롯 (slot)\n\n객체의 속성(attribute)를 기술하는 것으로 슬롯 이름과 값으로 구성된다.\n슬롯 값은 복수개의 `패싯`과 `데몬`으로 구성된다.\n\n- 패싯 (facet)\n  속성에 대한 부가적인 정보를 저장하기 위해 사용되며 아래와 같은 패싯 이름들을 사용할 수 있다.\n  - value: 속성 값\n  - data-type: 속성의 자료형\n  - default: 기본 값\n  - require: 슬롯에 들어갈 수 있는 값이 만족해야 할 제약조건\n\n- 데몬 (demon)\n  ![231022-154436](/posts/mid_03/231022-154436.png)\n\n  지정된 조건을 만족할 때 실행할 절차적 지식을 기술하는데 사용되며, 아래와 같은 데몬 이름들을 사용할 수 있다.\n  - if_needed: 슬롯 값을 알아야 할 때(즉, 사용하려고 할 때)\n  - if_added: 슬롯 값이 추가될 때\n  - if_removed: 슬롯 값이 제거될 때\n  - if_modified: 슬롯 값이 수정될 때\n\n### 클래스 프레임\n\n위에서 프레임을 설명할 때 사용한 프레임이 클래스 프레임이다.\n\n\u003ctip\u003e\n  하위 프레임이 상위 프레임을 상속받는 계층구조도 가질 수 있음.\n\u003c/tip\u003e\n\n### 인스턴스 프레임\n\n![231022-154657](/posts/mid_03/231022-154657.png)\n\n클래스 프레임을 특정 객체에 대한 정보로 표현하면 인스턴스 프레임이 된다.\n그냥 OOP와 같은 개념이다.\n\n---\n\n## 의미망 (Semantic network)\n\n![231022-184947](/posts/mid_03/231022-184947.png)\n\n노드와 방향성 간선으로 구성되는 그래프를 이용해 지식을 표현하는 방법으로, 이항 관계만을 표현한다.\n그렇기에 다항 관계도 이항 관계로 전개하여 표현해야 하는데, 그 때문에 관계(relation) 역시 객체로 간주하여 표현한다.\n\n![231022-185755](/posts/mid_03/231022-185755.png)\n\n- `is-a`\n  자식 is-a 부모, 인스턴스 is-a 클래스와 같은 관계의 간선을 표현한다.\n\n- `has-a`\n  전체 has-a 부분, 부분 part-of 전체와 같은 관계의 간선을 표현한다.\n\n\u003ctip\u003e\n  is-a, has-a는 추이적 관계를 만족하는데, 추이적 관계란, 3단논법과 같은 관계를 의미함.\n  \n  \u003e is-a(팽귄, 조류) $\\wedge$ is-a(조류, 동물) \u0026rarr; is-a(팽귄, 동물)\n\u003c/tip\u003e\n\n지식을 시각적으로 표현할 수 있어 직관적으로 이해할 수 있고, 노드 추가 및 변경이 자유롭다는 장점이 있다.\n하지만, 양이 많아지면 관리가 복잡해지고, 개념이나 관계를 임의로 정의하기에 통일성이 떨어진다는 단점이 있다.\n\n### 추론\n\n상속관계를 이용해서 추론한다.\n예로 들어 '바둑기사의 키는?' 이라는 질문은 다음과 같이 추론할 수 있다.\n\n![231022-190024](/posts/mid_03/231022-190024.png)\n\n뿐만 아니라, 주어진 지식으로부터 새로운 사실을 이끌어내는 추론도 가능하다.\n예로 들어 '사람1이 사람2에게 사물1을 준다'는 지식으로부터, '사람2는 사물1을 소유하게 된다'는 사실을 추론한다.\n\n![231022-190213](/posts/mid_03/231022-190213.png)\n\n### 프레임으로 변환\n\n![231022-190324](/posts/mid_03/231022-190324.png)\n\n노드별로 프레임으로 변환할 수 있는데, 노드에서 나가는 간선들을 슬롯으로 구성하면 된다.\n\n---\n\n## 스크립트 (Script)\n\n일반적으로 발생할 수 있는 전형적인 상황에 대한 절차적 지식을 일목요연하게 표현한 것이다.\n\n![231022-190644](/posts/mid_03/231022-190644.png)\n\n- 진입 조건\n  스크립트에 기술된 사건들이 일어나기 전에 만족되어야 하는 전제조건\n\n- 역할자\n  스크립트에 관련된 사람, 대상\n\n- 자산\n  사건 진행 과정에서 사용되는 객체\n\n- 트랙\n  스크립트에서 발생할 수 있는 사건들이 변형된 형태 식별자 (장소)\n\n- 장면\n  실제 일어나는 일련의 사건\n  \n- 결과 조건\n  스크립트의 장면에 있는 사건들이 일어난 후에 만족되는 조건","slug":"univ_ai/mid_03","readingMinutes":6,"wordCount":401},{"title":"게임에서의 탐색 및 최적화","description":"게임 트리를 탐색하는 기법과 최적화에 대해 알아봅니다.","icon":"","image":"","tags":["Mini-Max algorithm","Alpha-Beta prunning","Monte Carlo","Backtracking search","Constraint propagation","Genetic algorithm","Regression"],"draft":false,"date":"2023-10-21 / 22:53","content":"\n## 게임 트리\n\n`상대가 있는 게임`에서 자신과 상대방의 가능한 게임 상태를 나타낸 트리.\n자신의 턴인지, 상대의 턴인지에 따라 탐색하는 방식이 다르게 적용됨.\n(나에겐 유리하게, 상대에겐 불리하게)\n\n정해진 시간 내에 최대한 많은 수를 보는 것이 유리하기 때문에 탐색 효율을 높이는 것이 중요하다.\n\n### Mini-max Algorithm\n\n특이하게 단말 노드로부터 위로 올라가면서 최소-최대 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 값을 선택하는 방법이다.\n\n자신의 턴인 Max 노드에서는 자신에게 유리한 값을 선택하고,\n상대의 턴인 Min 노드에서는 상대에게 불리한 값을 선택하는 방식을 취한다.\n\n![231021-230224](/posts/mid_02/231021-230224.png)\n\n하지만 트리가 넓을 수록 모든 상태공간을 탐색하는건 시간상 너무 오래 걸리기 때문에 최적화 기법이 들어가야 한다.\n바로 **$\\alpha - \\beta$ 가지치기(prunning)** 기법이다.\n\n검토해 볼 필요가 없는 부분을 탐색하지 않도록 하는 기법인데, 어떻게 해야 검토할 필요가 없다는 걸 알 수 있을까?\n\n깊이 우선 탐색(DFS)로 제한 깊이까지 탐색을 하면서 Min, Max 노드의 $\\alpha$, $\\beta$값을 업데이트 하는데, 각 $\\alpha$, $\\beta$값은 다음과 같은 값을 저장한다.\n\n- $\\alpha$\n  Max 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최댓값을 저장함\n\n- $\\beta$\n  Min 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최솟값을 저장함\n\n이 때, 탐색 후 값을 업데이트 하다가 **$\\alpha \\geq \\beta$** 되는 순간이 오는데, 그 때부터 나머지 자식노드는 탐색할 필요가 없어진다.\n그 이유는, 상한선($\\alpha$)과 하한선($\\beta$)이 정해질 때, 그 부모노드의 상한선과 하한선을 넘지 못하면 부모노드를 업데이트 할 수 없기에, 업데이트를 할 가능성이 없다면 가지치기를 해버리는 것이다.\n\n알고리즘의 이해가 안된다면 아래 영상을 참고하면 좋을 거 같다.\n\n\u003cYT id=\"_i-lZcbWkps\" /\u003e\n\n속성으로 빠르게 탐색하고 싶다면 이런 방식으로 탐색해도 된다.\n\n\u003cYT id=\"6qN5ReC2SUA\" /\u003e\n\n빠르게 업데이트 가능한 조건을 적어놓고, 그 조건이 업데이트가 절대로 불가능하다면 나머지 노드를 가지치기 하는 방식이다.\n\n### 몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)\n\n![231022-003000](/posts/mid_02/231022-003000.png)\n\n탐색 공간을 무작위 표본추출을 하면서 탐색 트리를 확장하여 가장 좋아보이는 것을 선택하는 휴리스틱 탐색 방법으로,\n시간이 허용되는 동안 위의 4단계를 반복하여 시뮬레이션 및 트리를 확장한다.\n\n1. 선택\n  선택은 **트리 정책**을 적용하여 선택한다.\n  정책은 개발자 마음대로 정하는 거지만, 보통 승률과 노드 방문횟수를 고려하여 선택한다.\n  일반적으로 `승률이 높으며`, `방문횟수가 적은` 노드에 우선권을 부여한다 (UCB, Upper Confidence Bound 정책).\n\n2. 확장\n  단말 노드에서 트리 정책에 따라 노드를 추가한다.\n\n3. 시뮬레이션\n  기본 정책에 의한 `몬테카를로 시뮬레이션`을 적용한다.\n  무작위 선택, 또는 약간 똑똑한 방법으로 게임이 끝날 때 까지 진행한다.\n\n  \u003ctip\u003e\n  `몬테카를로 시뮬레이션`\n  \u003cbr /\u003e\n  특정 확률 분포로 부터 무작위 표본(또는 약간 똑똑한 방법으로)을 생성하고, 이 표본에 따라 행동을 하는 과정을 반복하여 결과를 확인하고 이 과정을 반복해 최정 결정을 하는 것.\n  \u003cbr /\u003e\n  특정 상태의 유불리를 상태판단함수로 판단하는 것이 아닌, 시뮬레이션으로 판단하게 된다.\n  \u003c/tip\u003e\n\n4. 역전파\n  게임의 결과를 단말 노드에서 루트 노드까지 올라가면서 반영한다.\n\n---\n\n## 제약조건 만족 문제\n\n주어진 제약조건을 만족하는 조합 해(combination solution)을 찾는 문제로 N-Queens problem과 같은 문제가 이에 해당한다.\n\n### 백 트래킹 탐색 (Backtracking search)\n\n깊이 우선 탐색(DFS)을 하는 것처럼 변수에 허용되는 값을 하나씩 대입해보고, 가능한 모든 값을 대입했는데도 만족하는 것이 없으면 이전 단계로 돌아가서 이전 단계의 변수에 다른 값을 대입하는 전형적인 백 트래킹 방식이다.\n\n### 제약조건 전파 (Constraint propagation)\n\n인접 변수 간의 제약 조건에 따라 각 변수에 허용될 수 없는 값들을 제거하는 방식으로, 이름 그대로 주변에 제약조건을 전파하여 선택 가능한 가지수를 줄여가는 방식이다.\n\n![231022-004410](/posts/mid_02/231022-004410.png)\n\nA에 1을 선택하는 순간 B\\~D에 각각 제약사항이 전파되어 B\\~D에서 선택할 수 있는 가지수가 제한된다.\n여기서 B가 3을 선택하는 순간 C, D에 각각 제약사항이 또 전파되는데, 이 때 C는 더이상 아무것도 선택할 수 없기에 이전 스탭에서 다른 제약사항을 걸어야 한다.\n\n---\n\n## 최적화\n\n여러가지 가능, 혀용되는 값들 중에서 주어진 기준을 가장 잘 만족하는 것을 선택하는 것으로, 크게 `조합 최적화`와 `함수 최적화`로 나뉜다.\n\n### 조합 최적화\n\nTSP와 같이 주어진 항목들의 조합으로 해가 표현되는 최적화 문제로, 이 경우에는 경로의 길이를 최소화 하는 문제이다.\n\n![231022-005505](/posts/mid_02/231022-005505.png)\n\n이를 달성하기 위해 생물의 진화를 모방한 집단 기반 확률적 탐색 기법인 `유전 알고리즘`을 사용하기도 한다.\n\n개체는 염색체로 표현되며 다음과 같이 기술된다.\n\n![231022-005704](/posts/mid_02/231022-005704.png)\n\n이런 염색체들의 집합을 `모집단`이라고 하는데, 이런 모집단(후보해)가 문제의 해로서 적합한 정도를 `적합도 함수`가 판단하게 되고, 적합하다면 최적 개체로서 알고리즘이 종료되지만, 적합하지 않다면 **진화의 과정**을 거치게 된다.\n\n모집단이 진화를 할 때는 우선 `부모 모집단` 중 개체를 선택하게 되는데, **가능한 높은 적합도의 개체가 선택되도록 확률을 높게** 조정한다.\n자연선택과 같이 **랜덤**한 요소가 있어야 하기에 반드시 적합한 녀석이 선택되지는 않는다.\n\n이후에는 선택된 부모 개체가 `유전 연산`을 거쳐 자식 개체를 양산하게 되는데, 유전 연산에는 다음과 같은 연산을 고려할 수 있다.\n\n![231022-010201](/posts/mid_02/231022-010201.png)\n\n이후에는 생성된 여러 자식 개체를 이용해서 `세대를 교체`하게 되는데, **최대한 많은 우수한 계체가 다음 세대에 유지**될 수 있도록 `엘리트주의`를 적용한다.\n\n### 목적 최적화\n\n어떤 목적 함수(Objective function)가 있을 때, 이 함수를 최대로 하거나 최소로 하는 변수 값을 찾는 최적화 문제이다.\n\n![231022-010440](/posts/mid_02/231022-010440.png)\n\n`최소 평균제곱법`을 사용해서 회귀(Regression) 문제의 최적함수를 찾거나,\n\n![231022-010602](/posts/mid_02/231022-010602.png)\n\n함수의 최소값 위치를 찾는 문제에서 `경사 하강법`과 같은 방법을 사용할 수 있다.","slug":"univ_ai/mid_02","readingMinutes":11,"wordCount":724},{"title":"상태공간 \u0026 탐색","description":"상태공간과 탐색의 의미와 예시를 알아봅니다.","icon":"","image":"","tags":["Depth First Search","Breadth First Search","Depth Limited Search","Best First Search","Beam Search","A* Algorithm"],"draft":false,"date":"2023-09-12 / 15:44","content":"\n## 상태공간\n\n문제 해결 과정에서 초기 상태로부터 도달할 수 있는 모든 상태들의 집합을 의미한다.\n한 마디로 `문제의 해가 될 가능성`이 있는 모든 상태들의 집합을 의미한다.\n\n## 탐색\n\n상태공간에서 최적의 해를 찾기위해 공간을 체계적으로 찾아보는 것을 의미한다.\n탐색은 아래와 같은 방식으로 크게 구분지을 수 있다.\n\n1. 맹목적 탐색\n2. 정보이용 탐색\n\n이렇게 구분짓는 이유는 탐색의 방식에 따라 달라지는데,\n탐색 방식이 다양해 질 수 밖에 없는 이유는 일반적인 문제에서는 상태공간이 매우 크기 때문에\n미리 공간 그래프를 그릴 수 없어 탐색 과정에서 그래프를 생성할 수 밖에 없기 때문이다.\n\n---\n\n## 맹목적 탐색\n\n정해진 순서에 따라 상태공간 그래프를 점차 생성해 가면서 해를 탐색하는 방법을 의미한다.\n\n### 깊이 우선 탐색 (Depth-first search)\n\n![231021-223045](/posts/mid_01/231021-223045.png)\n\n초기 노드부터 깊이가 깊어지는 방향으로 우선 탐색하는 기법.\n더이상 진행할 수 없다면 백 트리킹으로 돌아와 다음 노드 탐색.\n\n루트 노드에서 현재 노드까지의 경로 하나만 유지한다는 특징이 있기에 메모리 공간 사용이 효율적이라는 장점이 있다.\n하지만, 깊이가 무한히 깊어지는 무한루프의 가능성 때문에 항상 최단 경로의 해를 보장할 수 없다는 단점이 있다.\n\n### 너비 우선 탐색 (Breadth-first search)\n\n![231021-223311](/posts/mid_01/231021-223311.png)\n\n초기 노드부터 시작하여 모든 자식 노드를 확장하여 탐색하는 기법.\n목표 노드가 없다면 단말 노드에서 다시 자식노드 확장 탐색.\n\n최단 경로의 해를 보장하지만, 메모리 효율적이지 못하다.\n\n### 깊이 제한 탐색 (Depth-limited search)\n\n![231021-223510](/posts/mid_01/231021-223510.png)\n\n기본적인 탐색 방식은 깊이 우선 탐색 방식임.\n단, 깊이에 제한을 둬서 특정 깊이 이하로는 탐색을 진행하지 않고 백 트래킹 하는 것이 특징임.\n특정 깊이에서 목표를 찾지 못한 경우 깊이를 늘려가며 처음부터 다시 탐색을 진행함.\n\n최단 경로의 해를 보장하며, 메모리 사용도 효율적이다.\n상위 노드는 반복해서 탐색하기에 약간의 비효율성이 있으나, 무시할만한 수준임.\n\n즉 맹목적 탐색시에는 이 방식을 우선적으로 고려하는 것이 좋음.\n\n---\n\n## 정보이용 탐색\n\n휴리스틱한 방법으로 목표까지의 예상 비용을 구하고, 그 값에 의거해 순간순간 최선의 선택을 해가며 탐색하는 방법을 의미한다.\n\n\u003ctip\u003e\n  `휴리스틱 (heuristic)`\n  신속하게 어림짐작 하는 것.\n\u003c/tip\u003e\n\n### 언덕 오르기 방법 (Hill climbing method)\n\n![231021-224206](/posts/mid_01/231021-224206.png)\n\n현재 노드에서 휴리스틱에 의한 평가값이 가장 좋은 이웃 노드 하나를 확장해가는 탐색기법.\n단, 국소 최적해에 빠질 가능성이 있다.\n(경사 하강법과 유사)\n\n### 최상 우선 탐색 (Best-first search)\n\n확장 중인 노드들 중에서 목표 노드까지 남은 거리가 가장 짧은 노드를 확장하여 탐색하는 기법.\n일종의 그리디한 방식임.\n\n![231021-224403](/posts/mid_01/231021-224403.png)\n\n예시로 휴리스틱 함수를 제자리가 아닌 타일의 개수라고 할 때, 다음과 같은 순서로 탐색을 진행하게 된다.\n\n\u003e a \u0026rarr; c \u0026rarr; e/f \u0026rarr; h \u0026rarr; j\n\n### 빔 탐색 (Beam search)\n\n최상 우선 탐색(BFS) 의 확장판으로, 휴리스틱에 의한 평가값이 우수한 일정 개수(K개)의 확장 가능한 노드만을 메모리에서 관리하면서 탐색.\n\n![231021-224723](/posts/mid_01/231021-224723.png)\n\n예시로 K=2일 때, A~E를 일단 탐색하고, 평가값이 우수한 B, E를 제외한 노드는 메모리에서 제거하며 B, E에서 그 자식노드에 대해 같은 방식을 적용하며 탐색한다.\n\n### A* 알고리즘 (A-star algorithm)\n\n최상 우선 탐색(BFS) 의 개선판으로, 휴리스틱에 의한 평가값 + 현재까지의 코스트의 결과인 휴리스틱한 전체 비용을 기준으로 탐색하는 기법.\n\n![231021-225028](/posts/mid_01/231021-225028.png)\n\n최초 상태를 탐색한 후, 그 자식 노드 3개의 휴리스틱한 전체 비용을 계산하면 `1(현재까지의 코스트)+3(휴리스틱 평가값)`의 값을 갖는 가운데 자식 노드가 비용이 가장 작기에 다음 탐색 대상으로 한다.\n\n이런 식으로 **탐색한 모든 노드를 메모리 상에서 관리**하며, 그 순간 휴리스틱 전체 비용이 가장 낮은 노드를 다음 탐색 대상으로 삼는다.","slug":"univ_ai/mid_01","readingMinutes":7,"wordCount":479},{"title":"대학 - 인공지능","description":"3학년 2학기 인공지능 수업 아카이브","icon":"","image":"","tags":[],"draft":false,"date":"2023-09-05 / 16:11","content":"","slug":"univ_ai/index","readingMinutes":0,"wordCount":1}],"mdx":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h2: \"h2\",\n    a: \"a\",\n    span: \"span\",\n    p: \"p\",\n    code: \"code\",\n    br: \"br\",\n    h3: \"h3\",\n    img: \"img\",\n    strong: \"strong\",\n    math: \"math\",\n    semantics: \"semantics\",\n    mrow: \"mrow\",\n    mi: \"mi\",\n    mo: \"mo\",\n    annotation: \"annotation\",\n    ul: \"ul\",\n    li: \"li\",\n    ol: \"ol\",\n    hr: \"hr\"\n  }, _provideComponents(), props.components), {YT} = _components;\n  if (!YT) _missingMdxReference(\"YT\", true);\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.h2, {\n      id: \"게임-트리\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#게임-트리\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"게임 트리\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"상대가 있는 게임\"\n      }), \"에서 자신과 상대방의 가능한 게임 상태를 나타낸 트리.\", _jsx(_components.br, {}), \"\\n\", \"자신의 턴인지, 상대의 턴인지에 따라 탐색하는 방식이 다르게 적용됨.\", _jsx(_components.br, {}), \"\\n\", \"(나에겐 유리하게, 상대에겐 불리하게)\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"정해진 시간 내에 최대한 많은 수를 보는 것이 유리하기 때문에 탐색 효율을 높이는 것이 중요하다.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"mini-max-algorithm\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#mini-max-algorithm\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"Mini-max Algorithm\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"특이하게 단말 노드로부터 위로 올라가면서 최소-최대 연산을 반복하여 자신이 선택할 수 있는 방법 중 가장 좋은 값을 선택하는 방법이다.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"자신의 턴인 Max 노드에서는 자신에게 유리한 값을 선택하고,\", _jsx(_components.br, {}), \"\\n\", \"상대의 턴인 Min 노드에서는 상대에게 불리한 값을 선택하는 방식을 취한다.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231021-230224.png\",\n        alt: \"231021-230224\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"하지만 트리가 넓을 수록 모든 상태공간을 탐색하는건 시간상 너무 오래 걸리기 때문에 최적화 기법이 들어가야 한다.\", _jsx(_components.br, {}), \"\\n\", \"바로 \", _jsxs(_components.strong, {\n        children: [_jsx(_components.span, {\n          className: \"math math-inline\",\n          children: _jsxs(_components.span, {\n            className: \"katex\",\n            children: [_jsx(_components.span, {\n              className: \"katex-mathml\",\n              children: _jsx(_components.math, {\n                xmlns: \"http://www.w3.org/1998/Math/MathML\",\n                children: _jsxs(_components.semantics, {\n                  children: [_jsxs(_components.mrow, {\n                    children: [_jsx(_components.mi, {\n                      children: \"α\"\n                    }), _jsx(_components.mo, {\n                      children: \"−\"\n                    }), _jsx(_components.mi, {\n                      children: \"β\"\n                    })]\n                  }), _jsx(_components.annotation, {\n                    encoding: \"application/x-tex\",\n                    children: \"\\\\alpha - \\\\beta\"\n                  })]\n                })\n              })\n            }), _jsxs(_components.span, {\n              className: \"katex-html\",\n              \"aria-hidden\": \"true\",\n              children: [_jsxs(_components.span, {\n                className: \"base\",\n                children: [_jsx(_components.span, {\n                  className: \"strut\",\n                  style: {\n                    height: \"0.6667em\",\n                    verticalAlign: \"-0.0833em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mord mathnormal\",\n                  style: {\n                    marginRight: \"0.0037em\"\n                  },\n                  children: \"α\"\n                }), _jsx(_components.span, {\n                  className: \"mspace\",\n                  style: {\n                    marginRight: \"0.2222em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mbin\",\n                  children: \"−\"\n                }), _jsx(_components.span, {\n                  className: \"mspace\",\n                  style: {\n                    marginRight: \"0.2222em\"\n                  }\n                })]\n              }), _jsxs(_components.span, {\n                className: \"base\",\n                children: [_jsx(_components.span, {\n                  className: \"strut\",\n                  style: {\n                    height: \"0.8889em\",\n                    verticalAlign: \"-0.1944em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mord mathnormal\",\n                  style: {\n                    marginRight: \"0.05278em\"\n                  },\n                  children: \"β\"\n                })]\n              })]\n            })]\n          })\n        }), \" 가지치기(prunning)\"]\n      }), \" 기법이다.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"검토해 볼 필요가 없는 부분을 탐색하지 않도록 하는 기법인데, 어떻게 해야 검토할 필요가 없다는 걸 알 수 있을까?\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"깊이 우선 탐색(DFS)로 제한 깊이까지 탐색을 하면서 Min, Max 노드의 \", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"α\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\alpha\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.4306em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.0037em\"\n                },\n                children: \"α\"\n              })]\n            })\n          })]\n        })\n      }), \", \", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"β\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\beta\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.8889em\",\n                  verticalAlign: \"-0.1944em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.05278em\"\n                },\n                children: \"β\"\n              })]\n            })\n          })]\n        })\n      }), \"값을 업데이트 하는데, 각 \", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"α\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\alpha\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.4306em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.0037em\"\n                },\n                children: \"α\"\n              })]\n            })\n          })]\n        })\n      }), \", \", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"β\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\beta\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.8889em\",\n                  verticalAlign: \"-0.1944em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.05278em\"\n                },\n                children: \"β\"\n              })]\n            })\n          })]\n        })\n      }), \"값은 다음과 같은 값을 저장한다.\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsxs(_components.p, {\n          children: [_jsx(_components.span, {\n            className: \"math math-inline\",\n            children: _jsxs(_components.span, {\n              className: \"katex\",\n              children: [_jsx(_components.span, {\n                className: \"katex-mathml\",\n                children: _jsx(_components.math, {\n                  xmlns: \"http://www.w3.org/1998/Math/MathML\",\n                  children: _jsxs(_components.semantics, {\n                    children: [_jsx(_components.mrow, {\n                      children: _jsx(_components.mi, {\n                        children: \"α\"\n                      })\n                    }), _jsx(_components.annotation, {\n                      encoding: \"application/x-tex\",\n                      children: \"\\\\alpha\"\n                    })]\n                  })\n                })\n              }), _jsx(_components.span, {\n                className: \"katex-html\",\n                \"aria-hidden\": \"true\",\n                children: _jsxs(_components.span, {\n                  className: \"base\",\n                  children: [_jsx(_components.span, {\n                    className: \"strut\",\n                    style: {\n                      height: \"0.4306em\"\n                    }\n                  }), _jsx(_components.span, {\n                    className: \"mord mathnormal\",\n                    style: {\n                      marginRight: \"0.0037em\"\n                    },\n                    children: \"α\"\n                  })]\n                })\n              })]\n            })\n          }), _jsx(_components.br, {}), \"\\n\", \"Max 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최댓값을 저장함\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsxs(_components.p, {\n          children: [_jsx(_components.span, {\n            className: \"math math-inline\",\n            children: _jsxs(_components.span, {\n              className: \"katex\",\n              children: [_jsx(_components.span, {\n                className: \"katex-mathml\",\n                children: _jsx(_components.math, {\n                  xmlns: \"http://www.w3.org/1998/Math/MathML\",\n                  children: _jsxs(_components.semantics, {\n                    children: [_jsx(_components.mrow, {\n                      children: _jsx(_components.mi, {\n                        children: \"β\"\n                      })\n                    }), _jsx(_components.annotation, {\n                      encoding: \"application/x-tex\",\n                      children: \"\\\\beta\"\n                    })]\n                  })\n                })\n              }), _jsx(_components.span, {\n                className: \"katex-html\",\n                \"aria-hidden\": \"true\",\n                children: _jsxs(_components.span, {\n                  className: \"base\",\n                  children: [_jsx(_components.span, {\n                    className: \"strut\",\n                    style: {\n                      height: \"0.8889em\",\n                      verticalAlign: \"-0.1944em\"\n                    }\n                  }), _jsx(_components.span, {\n                    className: \"mord mathnormal\",\n                    style: {\n                      marginRight: \"0.05278em\"\n                    },\n                    children: \"β\"\n                  })]\n                })\n              })]\n            })\n          }), _jsx(_components.br, {}), \"\\n\", \"Min 노드에서만 값이 업데이트되며, 현재까지 확보한 자식의 값 중 최솟값을 저장함\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"이 때, 탐색 후 값을 업데이트 하다가 \", _jsx(_components.strong, {\n        children: _jsx(_components.span, {\n          className: \"math math-inline\",\n          children: _jsxs(_components.span, {\n            className: \"katex\",\n            children: [_jsx(_components.span, {\n              className: \"katex-mathml\",\n              children: _jsx(_components.math, {\n                xmlns: \"http://www.w3.org/1998/Math/MathML\",\n                children: _jsxs(_components.semantics, {\n                  children: [_jsxs(_components.mrow, {\n                    children: [_jsx(_components.mi, {\n                      children: \"α\"\n                    }), _jsx(_components.mo, {\n                      children: \"≥\"\n                    }), _jsx(_components.mi, {\n                      children: \"β\"\n                    })]\n                  }), _jsx(_components.annotation, {\n                    encoding: \"application/x-tex\",\n                    children: \"\\\\alpha \\\\geq \\\\beta\"\n                  })]\n                })\n              })\n            }), _jsxs(_components.span, {\n              className: \"katex-html\",\n              \"aria-hidden\": \"true\",\n              children: [_jsxs(_components.span, {\n                className: \"base\",\n                children: [_jsx(_components.span, {\n                  className: \"strut\",\n                  style: {\n                    height: \"0.7719em\",\n                    verticalAlign: \"-0.136em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mord mathnormal\",\n                  style: {\n                    marginRight: \"0.0037em\"\n                  },\n                  children: \"α\"\n                }), _jsx(_components.span, {\n                  className: \"mspace\",\n                  style: {\n                    marginRight: \"0.2778em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mrel\",\n                  children: \"≥\"\n                }), _jsx(_components.span, {\n                  className: \"mspace\",\n                  style: {\n                    marginRight: \"0.2778em\"\n                  }\n                })]\n              }), _jsxs(_components.span, {\n                className: \"base\",\n                children: [_jsx(_components.span, {\n                  className: \"strut\",\n                  style: {\n                    height: \"0.8889em\",\n                    verticalAlign: \"-0.1944em\"\n                  }\n                }), _jsx(_components.span, {\n                  className: \"mord mathnormal\",\n                  style: {\n                    marginRight: \"0.05278em\"\n                  },\n                  children: \"β\"\n                })]\n              })]\n            })]\n          })\n        })\n      }), \" 되는 순간이 오는데, 그 때부터 나머지 자식노드는 탐색할 필요가 없어진다.\", _jsx(_components.br, {}), \"\\n\", \"그 이유는, 상한선(\", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"α\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\alpha\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.4306em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.0037em\"\n                },\n                children: \"α\"\n              })]\n            })\n          })]\n        })\n      }), \")과 하한선(\", _jsx(_components.span, {\n        className: \"math math-inline\",\n        children: _jsxs(_components.span, {\n          className: \"katex\",\n          children: [_jsx(_components.span, {\n            className: \"katex-mathml\",\n            children: _jsx(_components.math, {\n              xmlns: \"http://www.w3.org/1998/Math/MathML\",\n              children: _jsxs(_components.semantics, {\n                children: [_jsx(_components.mrow, {\n                  children: _jsx(_components.mi, {\n                    children: \"β\"\n                  })\n                }), _jsx(_components.annotation, {\n                  encoding: \"application/x-tex\",\n                  children: \"\\\\beta\"\n                })]\n              })\n            })\n          }), _jsx(_components.span, {\n            className: \"katex-html\",\n            \"aria-hidden\": \"true\",\n            children: _jsxs(_components.span, {\n              className: \"base\",\n              children: [_jsx(_components.span, {\n                className: \"strut\",\n                style: {\n                  height: \"0.8889em\",\n                  verticalAlign: \"-0.1944em\"\n                }\n              }), _jsx(_components.span, {\n                className: \"mord mathnormal\",\n                style: {\n                  marginRight: \"0.05278em\"\n                },\n                children: \"β\"\n              })]\n            })\n          })]\n        })\n      }), \")이 정해질 때, 그 부모노드의 상한선과 하한선을 넘지 못하면 부모노드를 업데이트 할 수 없기에, 업데이트를 할 가능성이 없다면 가지치기를 해버리는 것이다.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"알고리즘의 이해가 안된다면 아래 영상을 참고하면 좋을 거 같다.\"\n    }), \"\\n\", _jsx(YT, {\n      id: \"_i-lZcbWkps\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"속성으로 빠르게 탐색하고 싶다면 이런 방식으로 탐색해도 된다.\"\n    }), \"\\n\", _jsx(YT, {\n      id: \"6qN5ReC2SUA\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"빠르게 업데이트 가능한 조건을 적어놓고, 그 조건이 업데이트가 절대로 불가능하다면 나머지 노드를 가지치기 하는 방식이다.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"몬테카를로-트리-탐색-기법-monte-carlo-simulation\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#몬테카를로-트리-탐색-기법-monte-carlo-simulation\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-003000.png\",\n        alt: \"231022-003000\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"탐색 공간을 무작위 표본추출을 하면서 탐색 트리를 확장하여 가장 좋아보이는 것을 선택하는 휴리스틱 탐색 방법으로,\", _jsx(_components.br, {}), \"\\n\", \"시간이 허용되는 동안 위의 4단계를 반복하여 시뮬레이션 및 트리를 확장한다.\"]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsxs(_components.p, {\n          children: [\"선택\", _jsx(_components.br, {}), \"\\n\", \"선택은 \", _jsx(_components.strong, {\n            children: \"트리 정책\"\n          }), \"을 적용하여 선택한다.\", _jsx(_components.br, {}), \"\\n\", \"정책은 개발자 마음대로 정하는 거지만, 보통 승률과 노드 방문횟수를 고려하여 선택한다.\", _jsx(_components.br, {}), \"\\n\", \"일반적으로 \", _jsx(_components.code, {\n            children: \"승률이 높으며\"\n          }), \", \", _jsx(_components.code, {\n            children: \"방문횟수가 적은\"\n          }), \" 노드에 우선권을 부여한다 (UCB, Upper Confidence Bound 정책).\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsxs(_components.p, {\n          children: [\"확장\", _jsx(_components.br, {}), \"\\n\", \"단말 노드에서 트리 정책에 따라 노드를 추가한다.\"]\n        }), \"\\n\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"\\n\", _jsxs(_components.p, {\n          children: [\"시뮬레이션\", _jsx(_components.br, {}), \"\\n\", \"기본 정책에 의한 \", _jsx(_components.code, {\n            children: \"몬테카를로 시뮬레이션\"\n          }), \"을 적용한다.\", _jsx(_components.br, {}), \"\\n\", \"무작위 선택, 또는 약간 똑똑한 방법으로 게임이 끝날 때 까지 진행한다.\"]\n        }), \"\\n\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(\"tip\", {\n      children: [_jsx(_components.p, {\n        children: _jsx(_components.code, {\n          children: \"몬테카를로 시뮬레이션\"\n        })\n      }), _jsx(\"br\", {}), _jsx(_components.p, {\n        children: \"특정 확률 분포로 부터 무작위 표본(또는 약간 똑똑한 방법으로)을 생성하고, 이 표본에 따라 행동을 하는 과정을 반복하여 결과를 확인하고 이 과정을 반복해 최정 결정을 하는 것.\"\n      }), _jsx(\"br\", {}), _jsx(_components.p, {\n        children: \"특정 상태의 유불리를 상태판단함수로 판단하는 것이 아닌, 시뮬레이션으로 판단하게 된다.\"\n      })]\n    }), \"\\n\", _jsxs(_components.ol, {\n      start: \"4\",\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"역전파\", _jsx(_components.br, {}), \"\\n\", \"게임의 결과를 단말 노드에서 루트 노드까지 올라가면서 반영한다.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsxs(_components.h2, {\n      id: \"제약조건-만족-문제\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#제약조건-만족-문제\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"제약조건 만족 문제\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"주어진 제약조건을 만족하는 조합 해(combination solution)을 찾는 문제로 N-Queens problem과 같은 문제가 이에 해당한다.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"백-트래킹-탐색-backtracking-search\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#백-트래킹-탐색-backtracking-search\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"백 트래킹 탐색 (Backtracking search)\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"깊이 우선 탐색(DFS)을 하는 것처럼 변수에 허용되는 값을 하나씩 대입해보고, 가능한 모든 값을 대입했는데도 만족하는 것이 없으면 이전 단계로 돌아가서 이전 단계의 변수에 다른 값을 대입하는 전형적인 백 트래킹 방식이다.\"\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"제약조건-전파-constraint-propagation\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#제약조건-전파-constraint-propagation\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"제약조건 전파 (Constraint propagation)\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"인접 변수 간의 제약 조건에 따라 각 변수에 허용될 수 없는 값들을 제거하는 방식으로, 이름 그대로 주변에 제약조건을 전파하여 선택 가능한 가지수를 줄여가는 방식이다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-004410.png\",\n        alt: \"231022-004410\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"A에 1을 선택하는 순간 B~D에 각각 제약사항이 전파되어 B~D에서 선택할 수 있는 가지수가 제한된다.\", _jsx(_components.br, {}), \"\\n\", \"여기서 B가 3을 선택하는 순간 C, D에 각각 제약사항이 또 전파되는데, 이 때 C는 더이상 아무것도 선택할 수 없기에 이전 스탭에서 다른 제약사항을 걸어야 한다.\"]\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsxs(_components.h2, {\n      id: \"최적화\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#최적화\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"최적화\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"여러가지 가능, 혀용되는 값들 중에서 주어진 기준을 가장 잘 만족하는 것을 선택하는 것으로, 크게 \", _jsx(_components.code, {\n        children: \"조합 최적화\"\n      }), \"와 \", _jsx(_components.code, {\n        children: \"함수 최적화\"\n      }), \"로 나뉜다.\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"조합-최적화\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#조합-최적화\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"조합 최적화\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"TSP와 같이 주어진 항목들의 조합으로 해가 표현되는 최적화 문제로, 이 경우에는 경로의 길이를 최소화 하는 문제이다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-005505.png\",\n        alt: \"231022-005505\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"이를 달성하기 위해 생물의 진화를 모방한 집단 기반 확률적 탐색 기법인 \", _jsx(_components.code, {\n        children: \"유전 알고리즘\"\n      }), \"을 사용하기도 한다.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"개체는 염색체로 표현되며 다음과 같이 기술된다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-005704.png\",\n        alt: \"231022-005704\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"이런 염색체들의 집합을 \", _jsx(_components.code, {\n        children: \"모집단\"\n      }), \"이라고 하는데, 이런 모집단(후보해)가 문제의 해로서 적합한 정도를 \", _jsx(_components.code, {\n        children: \"적합도 함수\"\n      }), \"가 판단하게 되고, 적합하다면 최적 개체로서 알고리즘이 종료되지만, 적합하지 않다면 \", _jsx(_components.strong, {\n        children: \"진화의 과정\"\n      }), \"을 거치게 된다.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"모집단이 진화를 할 때는 우선 \", _jsx(_components.code, {\n        children: \"부모 모집단\"\n      }), \" 중 개체를 선택하게 되는데, \", _jsx(_components.strong, {\n        children: \"가능한 높은 적합도의 개체가 선택되도록 확률을 높게\"\n      }), \" 조정한다.\", _jsx(_components.br, {}), \"\\n\", \"자연선택과 같이 \", _jsx(_components.strong, {\n        children: \"랜덤\"\n      }), \"한 요소가 있어야 하기에 반드시 적합한 녀석이 선택되지는 않는다.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"이후에는 선택된 부모 개체가 \", _jsx(_components.code, {\n        children: \"유전 연산\"\n      }), \"을 거쳐 자식 개체를 양산하게 되는데, 유전 연산에는 다음과 같은 연산을 고려할 수 있다.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-010201.png\",\n        alt: \"231022-010201\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"이후에는 생성된 여러 자식 개체를 이용해서 \", _jsx(_components.code, {\n        children: \"세대를 교체\"\n      }), \"하게 되는데, \", _jsx(_components.strong, {\n        children: \"최대한 많은 우수한 계체가 다음 세대에 유지\"\n      }), \"될 수 있도록 \", _jsx(_components.code, {\n        children: \"엘리트주의\"\n      }), \"를 적용한다.\"]\n    }), \"\\n\", _jsxs(_components.h3, {\n      id: \"목적-최적화\",\n      children: [_jsx(_components.a, {\n        className: \"anchor\",\n        href: \"#목적-최적화\",\n        children: _jsx(_components.span, {\n          className: \"icon icon-link\"\n        })\n      }), \"목적 최적화\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"어떤 목적 함수(Objective function)가 있을 때, 이 함수를 최대로 하거나 최소로 하는 변수 값을 찾는 최적화 문제이다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-010440.png\",\n        alt: \"231022-010440\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.code, {\n        children: \"최소 평균제곱법\"\n      }), \"을 사용해서 회귀(Regression) 문제의 최적함수를 찾거나,\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/posts/mid_02/231022-010602.png\",\n        alt: \"231022-010602\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"함수의 최소값 위치를 찾는 문제에서 \", _jsx(_components.code, {\n        children: \"경사 하강법\"\n      }), \"과 같은 방법을 사용할 수 있다.\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}},"toc":[{"slug":"게임-트리","text":"게임 트리","subSections":[{"slug":"mini-max-algorithm","text":"Mini-max Algorithm"},{"slug":"몬테카를로-트리-탐색-기법-monte-carlo-simulation","text":"몬테카를로 트리 탐색 기법 (Monte Carlo Simulation)"}]},{"slug":"제약조건-만족-문제","text":"제약조건 만족 문제","subSections":[{"slug":"백-트래킹-탐색-backtracking-search","text":"백 트래킹 탐색 (Backtracking search)"},{"slug":"제약조건-전파-constraint-propagation","text":"제약조건 전파 (Constraint propagation)"}]},{"slug":"최적화","text":"최적화","subSections":[{"slug":"조합-최적화","text":"조합 최적화"},{"slug":"목적-최적화","text":"목적 최적화"}]}]},"__N_SSG":true},"page":"/blog/[...slugs]","query":{"slugs":["univ_ai","mid_02"]},"buildId":"deatTRx3qrRnvuKFWMv7Z","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>